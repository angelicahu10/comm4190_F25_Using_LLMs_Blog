<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Angelica">
<meta name="dcterms.date" content="2025-09-18">
<meta name="description" content="Inside Joy Buolamwini’s Great Mind">

<title>Unmasking: Unmasking AI – My Explorations With LLMs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-b99f487086fa9555d44c4d6901a13082.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Explorations With LLMs</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../www.linkedin.com/in/angelica-hu"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Unmasking: Unmasking AI</h1>
                  <div>
        <div class="description">
          Inside Joy Buolamwini’s Great Mind
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">LLMs</div>
                <div class="quarto-category">Prompting</div>
                <div class="quarto-category">Logic</div>
                <div class="quarto-category">[object Object]</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Angelica </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 18, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p><img src="unmasking.jpg" width="50%"></p>
<p>Thus far in the semester for this course, I have read a decent amount of Buolamwini’s Unmasking Ai Narrative. My initial thoughts were very intriguing since the idea that technology or artificial intellegence could have potential racial biases was one that never crossed my mine - perhaps that is because I am in a privilged position where I have personally never experienced any conflicts with it. However, that doesn’t imply that it is a problem in today’s society which Joy Buolmwini touches upon her personal experiences with facial recognition as a woman of color in this novel.</p>
<p>What I appreicate about her writing style is it’s narrative stucture and personability as she discusses how she started to study this phenomenon of ‘the coded gaze’ based on her background and throughout her education as a student. While I’m still in the beginning of the novel, when thing I do notice which I may not be the biggest fan of is how repetitive much of the content feels. It is important for Buolamwini to describe the problems she’s facing with the software, but when she constantly emphasizes it over and over, the line loses its significance in a way and almost becomes too victimazing. However, the points she brings up make me question why people who were initally building these kinds of softwares didn’t consider these biases and issues of representation in the first place. Is it because they didn’t matter as much during that time? Or a systemic issue? She mentiones that the idea of artificial intellegence was introduced in 1956 - so within roughly 69 years that its been able to develop, I think ideas regarding racial equality have significantly mattered more with the modern age and society.</p>
<p>I wonder what some LLMs think about whether or not there are issues wiht racial biases in artifical intellegence and what they have to say about themselves… Here’s what gpt4.0 had to say:</p>
<section id="user" class="level3">
<h3 class="anchored" data-anchor-id="user">USER</h3>
<p>Do you think artificial intelligence softwares, such as facial recognition, contain racial biases and may not be fully representative of all types of people?</p>
</section>
<section id="assistant" class="level3">
<h3 class="anchored" data-anchor-id="assistant">ASSISTANT</h3>
<p>Yes, there is substantial evidence suggesting that some artificial intelligence (AI) systems, including facial recognition software, can exhibit racial biases and may not perform equally well for all demographic groups. Several studies have highlighted disparities in the accuracy of facial recognition systems, particularly across different races, genders, and age groups. For instance, research has shown that these systems often have higher error rates for people with darker skin tones and for women, which can lead to misidentifications and unfair outcomes.</p>
<p>These biases can stem from several factors:</p>
<ol type="1">
<li><p><strong>Training Data</strong>: AI models are trained on large datasets that may not be representative of the full diversity of human faces. If a dataset is imbalanced—overrepresenting certain demographics while underrepresenting others—the model is more likely to perform poorly on underrepresented groups.</p></li>
<li><p><strong>Algorithm Design</strong>: The algorithms themselves can introduce or exacerbate biases, especially if they are not explicitly designed to account for demographic diversity.</p></li>
<li><p><strong>System Evaluation</strong>: The lack of thorough testing across diverse demographic groups can result in insufficient understanding of the system’s performance across those groups.</p></li>
</ol>
<p>To address these issues, it is crucial for developers to use diverse and representative datasets, implement fairness checks during the design process, regularly evaluate system performance across different demographics, and work towards transparency and accountability in AI systems. This can help mitigate biases and improve fairness and accuracy for all users.</p>
</section>
<section id="user-1" class="level3">
<h3 class="anchored" data-anchor-id="user-1">USER</h3>
<p>Why hasn’t this been a big issue of research in the public news? Are people actively taking steps to help solve this as the world becomes more increasingly AI focused?</p>
</section>
<section id="assistant-1" class="level3">
<h3 class="anchored" data-anchor-id="assistant-1">ASSISTANT</h3>
<p>The issue of bias in AI, particularly in technologies such as facial recognition, has increasingly become a topic of public research and media attention over the past several years. There are a few reasons why this topic may not have been front and center in public discourse until more recently:</p>
<ol type="1">
<li><p><strong>Awareness and Understanding</strong>: Initially, there was a general lack of awareness and understanding of how AI systems work and the potential for bias within them. As awareness has grown, so has the attention paid to these issues.</p></li>
<li><p><strong>Complexity of the Issue</strong>: The technical nature of AI and machine learning can make it difficult for the general public to engage with the specifics of algorithmic bias, which can limit broader discourse.</p></li>
<li><p><strong>Emergence of High-Profile Studies and Incidents</strong>: Media attention has increased in response to high-profile studies and incidents that highlight the real-world consequences of biased AI systems, such as cases of wrongful arrests due to misidentifications by facial recognition.</p></li>
<li><p><strong>Advocacy and Regulation</strong>: Advocacy groups and researchers have worked to raise awareness about the ethical implications of biased AI, leading to an increase in public and academic discussions, as well as policy considerations.</p></li>
<li><p><strong>Regulatory Developments</strong>: Governments and regulatory bodies around the world are becoming more attuned to the necessity of ensuring AI deployments are fair and equitable. This includes efforts to introduce regulations and guidelines that aim to mitigate bias and protect privacy.</p></li>
<li><p><strong>Corporate Responsiveness</strong>: Some technology companies are taking proactive measures to address bias in AI systems, such as diversifying training datasets, implementing fairness audits, and developing bias detection tools.</p></li>
<li><p><strong>Community and NGO Involvement</strong>: Non-governmental organizations and community groups have become vocal, ensuring that issues related to AI bias are addressed, especially when they impact marginalized groups.</p></li>
</ol>
<p>Overall, while more work is needed to ensure fair and equitable AI systems, there is growing recognition of these issues in both technical research and public discourse. This increase in attention is contributing to more focused research and policy initiatives aimed at reducing bias in AI technologies.</p>
</section>
<section id="user-2" class="level3">
<h3 class="anchored" data-anchor-id="user-2">USER</h3>
<p>Do you believe this is a pressing concern?</p>
</section>
<section id="assistant-2" class="level3">
<h3 class="anchored" data-anchor-id="assistant-2">ASSISTANT</h3>
<p>Yes, addressing bias in AI systems is a pressing concern. As AI technologies become more integrated into various aspects of everyday life—including law enforcement, hiring, healthcare, and financial services—the potential for biased systems to lead to unjust outcomes becomes more significant. Some key reasons why this is a critical issue include:</p>
<ol type="1">
<li><p><strong>Social Impact</strong>: Biased AI systems can perpetuate or even exacerbate existing social inequalities and discrimination. For example, inaccuracies in facial recognition could lead to biased surveillance practices, while biased hiring algorithms could perpetuate workplace inequality.</p></li>
<li><p><strong>Trust and Adoption</strong>: Trust in AI technologies is essential for their widespread adoption. If people believe these systems are biased or unfair, it can undermine public confidence and hinder the beneficial application of AI.</p></li>
<li><p><strong>Legal and Ethical Implications</strong>: There are significant legal and ethical considerations around the deployment of biased AI systems. Organizations need to ensure compliance with regulations and ethical standards to avoid legal challenges and protect individual rights.</p></li>
<li><p><strong>Accountability and Transparency</strong>: As AI systems make decisions that can affect people’s lives, it’s crucial to ensure these systems are transparent and accountable. Addressing bias is a key part of this, as it involves making AI systems understandable and justifiable to the people impacted by their decisions.</p></li>
<li><p><strong>Long-term Effects</strong>: The longer biased systems remain unaddressed, the more likely it is that they will lead to systemic issues, reinforcing biases and making it harder to correct them in the future.</p></li>
</ol>
<p>Efforts to tackle these challenges are ongoing, with researchers, policymakers, and organizations all contributing to developing solutions. These efforts include creating more representative datasets, developing algorithms that are robust to bias, setting industry standards, and establishing regulatory frameworks aimed at ensuring fairness and accountability in AI systems. Overall, addressing bias in AI is essential to harness the technology’s full potential for positive social impact.</p>
</section>
<section id="user-3" class="level3">
<h3 class="anchored" data-anchor-id="user-3">USER</h3>
<p>So you can verify that you may have racial biases…</p>
</section>
<section id="assistant-3" class="level3">
<h3 class="anchored" data-anchor-id="assistant-3">ASSISTANT</h3>
<p>As an AI language model, I don’t possess personal beliefs or the ability to experience bias in the way humans do. However, it is true that I am trained on vast datasets derived from internet sources, including a wide array of human communications. These datasets can potentially contain biased or unbalanced information, which means that biases present in the data can sometimes be reflected in the model’s outputs.</p>
<p>Efforts are made to minimize these biases during the training and development of AI models, but it’s a complex challenge and not entirely resolvable due to the nature of the data. Researchers and developers work continuously to identify and mitigate biases to improve fairness and accuracy.</p>
<p>If you notice any biased or inappropriate outputs, it’s important to provide feedback, as this helps improve the system over time. Ensuring AI systems are fair and equitable remains an ongoing process, requiring constant attention and improvement.</p>
</section>
<section id="user-4" class="level3">
<h3 class="anchored" data-anchor-id="user-4">USER</h3>
<p>I think I sense some biases, where do I report feedback and does it actually matter?</p>
</section>
<section id="assistant-4" class="level3">
<h3 class="anchored" data-anchor-id="assistant-4">ASSISTANT</h3>
<p>If you encounter biases or other issues in AI outputs, providing feedback is an important step in helping improve the systems. The process and effectiveness of reporting feedback can vary depending on the platform or organization managing the AI model. Here are some general steps you can take:</p>
<ol type="1">
<li><p><strong>Platform-Specific Feedback Channels</strong>: Many platforms have built-in feedback mechanisms where users can report issues. Look for a feedback option in the app or website where you’re interacting with the AI.</p></li>
<li><p><strong>Official Channels</strong>: Some organizations provide dedicated channels for feedback, such as support emails, forms on their website, or dedicated feedback portals.</p></li>
<li><p><strong>Community Forums</strong>: Participating in community forums, discussion boards, or groups related to the AI product can also be a way to provide feedback and share experiences with other users as well as developers.</p></li>
<li><p><strong>Surveys and User Studies</strong>: Occasionally, organizations conduct surveys or user studies and invite input on their systems. Participating in these can be a direct way to share your feedback.</p></li>
</ol>
<p>Giving feedback is crucial because:</p>
<ul>
<li><p><strong>Improvement and Mitigation</strong>: Feedback helps developers identify and prioritize areas that need improvement, particularly regarding bias and other ethical issues.</p></li>
<li><p><strong>User Experience</strong>: User reports can highlight common pain points or issues affecting the experience of the broader user community, leading to targeted enhancements.</p></li>
<li><p><strong>Awareness and Accountability</strong>: Providing feedback raises awareness among developers and stakeholders about specific or systemic issues, encouraging accountability and transparency.</p></li>
</ul>
<p>Organizations that actively seek and respond to user feedback are typically more effective in addressing and mitigating issues. However, the impact of your feedback can vary depending on the company’s commitment to addressing these concerns and their capacity to implement changes.</p>
<p>I found it interesting how honest the LLM was with the concerns I was addressing, and I’m honestly quite surprised that I don’t hear more of these concerns as the world becomes more increasingly reliant on AI for many complicated systems such as for criminal justice or healthcare. The LLM brought up many parallels between Unmasking AI and the concers that Buolamwini addresses in her book and they both try to understand the problem by navigating the basis of how these systems came to be whic</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/angelicahu10\.github\.io\/comm4190_F25_Using_LLMs_Blog\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>