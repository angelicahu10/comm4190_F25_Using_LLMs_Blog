{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29487c32-381d-49b2-a57f-58c28cdcc435",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Unmasking: Unmasking AI\"\n",
    "description: \"Inside Joy Buolamwini's Great Mind\"\n",
    "author: \"Angelica\"\n",
    "date: \"9/18/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Prompting\n",
    "  - Logic\n",
    "  - Living With a Book: Unmasking AI\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcec710-92f4-44af-8624-d89f93136d31",
   "metadata": {},
   "source": [
    "<img src='unmasking.jpg' width='50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f8b4b-62dc-451f-8fec-6a45368fdd43",
   "metadata": {},
   "source": [
    "Thus far in the semester for this course, I have read a decent amount of Buolamwini's Unmasking Ai Narrative. My initial thoughts were very intriguing since the idea that technology or artificial intellegence could have potential racial biases was one that never crossed my mine - perhaps that is because I am in a privilged position where I have personally never experienced any conflicts with it. However, that doesn't imply that it is a problem in today's society which Joy Buolmwini touches upon her personal experiences with facial recognition as a woman of color in this novel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6fa7f-cccd-482e-8a6d-d33c8aad435c",
   "metadata": {},
   "source": [
    "What I appreicate about her writing style is it's narrative stucture and personability as she discusses how she started to study this phenomenon of 'the coded gaze' based on her background and throughout her education as a student. While I'm still in the beginning of the novel, when thing I do notice which I may not be the biggest fan of is how repetitive much of the content feels. It is important for Buolamwini to describe the problems she's facing with the software, but when she constantly emphasizes it over and over, the line loses its significance in a way and almost becomes too victimazing. However, the points she brings up make me question why people who were initally building these kinds of softwares didn't consider these biases and issues of representation in the first place. Is it because they didn't matter as much during that time? Or a systemic issue? She mentiones that the idea of artificial intellegence was introduced in 1956 - so within roughly 69 years that its been able to develop, I think ideas regarding racial equality have significantly mattered more with the modern age and society."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33328362-7b6b-4f98-818e-fd9746069964",
   "metadata": {},
   "source": [
    "I wonder what some LLMs think about whether or not there are issues wiht racial biases in artifical intellegence and what they have to say about themselves...\n",
    "Here's what gpt4.0 had to say:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14866980-026f-4fdb-b054-d931c9bf7b5d",
   "metadata": {},
   "source": [
    "### USER\n",
    "Do you think artificial intelligence  softwares, such as facial recognition, contain racial biases and may not be fully representative of all types of people?\n",
    "\n",
    "### ASSISTANT\n",
    "Yes, there is substantial evidence suggesting that some artificial intelligence (AI) systems, including facial recognition software, can exhibit racial biases and may not perform equally well for all demographic groups. Several studies have highlighted disparities in the accuracy of facial recognition systems, particularly across different races, genders, and age groups. For instance, research has shown that these systems often have higher error rates for people with darker skin tones and for women, which can lead to misidentifications and unfair outcomes.\n",
    "\n",
    "These biases can stem from several factors:\n",
    "\n",
    "1. **Training Data**: AI models are trained on large datasets that may not be representative of the full diversity of human faces. If a dataset is imbalanced—overrepresenting certain demographics while underrepresenting others—the model is more likely to perform poorly on underrepresented groups.\n",
    "\n",
    "2. **Algorithm Design**: The algorithms themselves can introduce or exacerbate biases, especially if they are not explicitly designed to account for demographic diversity.\n",
    "\n",
    "3. **System Evaluation**: The lack of thorough testing across diverse demographic groups can result in insufficient understanding of the system's performance across those groups.\n",
    "\n",
    "To address these issues, it is crucial for developers to use diverse and representative datasets, implement fairness checks during the design process, regularly evaluate system performance across different demographics, and work towards transparency and accountability in AI systems. This can help mitigate biases and improve fairness and accuracy for all users.\n",
    "\n",
    "### USER\n",
    "Why hasn’t this been a big issue of research in the public news? Are people actively taking steps to help solve this as the world becomes more increasingly AI focused?\n",
    "\n",
    "### ASSISTANT\n",
    "The issue of bias in AI, particularly in technologies such as facial recognition, has increasingly become a topic of public research and media attention over the past several years. There are a few reasons why this topic may not have been front and center in public discourse until more recently:\n",
    "\n",
    "1. **Awareness and Understanding**: Initially, there was a general lack of awareness and understanding of how AI systems work and the potential for bias within them. As awareness has grown, so has the attention paid to these issues.\n",
    "\n",
    "2. **Complexity of the Issue**: The technical nature of AI and machine learning can make it difficult for the general public to engage with the specifics of algorithmic bias, which can limit broader discourse.\n",
    "\n",
    "3. **Emergence of High-Profile Studies and Incidents**: Media attention has increased in response to high-profile studies and incidents that highlight the real-world consequences of biased AI systems, such as cases of wrongful arrests due to misidentifications by facial recognition.\n",
    "\n",
    "4. **Advocacy and Regulation**: Advocacy groups and researchers have worked to raise awareness about the ethical implications of biased AI, leading to an increase in public and academic discussions, as well as policy considerations.\n",
    "\n",
    "5. **Regulatory Developments**: Governments and regulatory bodies around the world are becoming more attuned to the necessity of ensuring AI deployments are fair and equitable. This includes efforts to introduce regulations and guidelines that aim to mitigate bias and protect privacy.\n",
    "\n",
    "6. **Corporate Responsiveness**: Some technology companies are taking proactive measures to address bias in AI systems, such as diversifying training datasets, implementing fairness audits, and developing bias detection tools.\n",
    "\n",
    "7. **Community and NGO Involvement**: Non-governmental organizations and community groups have become vocal, ensuring that issues related to AI bias are addressed, especially when they impact marginalized groups.\n",
    "\n",
    "Overall, while more work is needed to ensure fair and equitable AI systems, there is growing recognition of these issues in both technical research and public discourse. This increase in attention is contributing to more focused research and policy initiatives aimed at reducing bias in AI technologies.\n",
    "\n",
    "### USER\n",
    "Do you believe this is a pressing concern?\n",
    "\n",
    "### ASSISTANT\n",
    "Yes, addressing bias in AI systems is a pressing concern. As AI technologies become more integrated into various aspects of everyday life—including law enforcement, hiring, healthcare, and financial services—the potential for biased systems to lead to unjust outcomes becomes more significant. Some key reasons why this is a critical issue include:\n",
    "\n",
    "1. **Social Impact**: Biased AI systems can perpetuate or even exacerbate existing social inequalities and discrimination. For example, inaccuracies in facial recognition could lead to biased surveillance practices, while biased hiring algorithms could perpetuate workplace inequality.\n",
    "\n",
    "2. **Trust and Adoption**: Trust in AI technologies is essential for their widespread adoption. If people believe these systems are biased or unfair, it can undermine public confidence and hinder the beneficial application of AI.\n",
    "\n",
    "3. **Legal and Ethical Implications**: There are significant legal and ethical considerations around the deployment of biased AI systems. Organizations need to ensure compliance with regulations and ethical standards to avoid legal challenges and protect individual rights.\n",
    "\n",
    "4. **Accountability and Transparency**: As AI systems make decisions that can affect people's lives, it's crucial to ensure these systems are transparent and accountable. Addressing bias is a key part of this, as it involves making AI systems understandable and justifiable to the people impacted by their decisions.\n",
    "\n",
    "5. **Long-term Effects**: The longer biased systems remain unaddressed, the more likely it is that they will lead to systemic issues, reinforcing biases and making it harder to correct them in the future.\n",
    "\n",
    "Efforts to tackle these challenges are ongoing, with researchers, policymakers, and organizations all contributing to developing solutions. These efforts include creating more representative datasets, developing algorithms that are robust to bias, setting industry standards, and establishing regulatory frameworks aimed at ensuring fairness and accountability in AI systems. Overall, addressing bias in AI is essential to harness the technology's full potential for positive social impact.\n",
    "\n",
    "### USER\n",
    "So you can verify that you may have racial biases…\n",
    "\n",
    "### ASSISTANT\n",
    "As an AI language model, I don't possess personal beliefs or the ability to experience bias in the way humans do. However, it is true that I am trained on vast datasets derived from internet sources, including a wide array of human communications. These datasets can potentially contain biased or unbalanced information, which means that biases present in the data can sometimes be reflected in the model’s outputs.\n",
    "\n",
    "Efforts are made to minimize these biases during the training and development of AI models, but it's a complex challenge and not entirely resolvable due to the nature of the data. Researchers and developers work continuously to identify and mitigate biases to improve fairness and accuracy.\n",
    "\n",
    "If you notice any biased or inappropriate outputs, it’s important to provide feedback, as this helps improve the system over time. Ensuring AI systems are fair and equitable remains an ongoing process, requiring constant attention and improvement.\n",
    "\n",
    "### USER\n",
    "I think I sense some biases, where do I report feedback and does it actually matter?\n",
    "\n",
    "### ASSISTANT\n",
    "If you encounter biases or other issues in AI outputs, providing feedback is an important step in helping improve the systems. The process and effectiveness of reporting feedback can vary depending on the platform or organization managing the AI model. Here are some general steps you can take:\n",
    "\n",
    "1. **Platform-Specific Feedback Channels**: Many platforms have built-in feedback mechanisms where users can report issues. Look for a feedback option in the app or website where you're interacting with the AI.\n",
    "\n",
    "2. **Official Channels**: Some organizations provide dedicated channels for feedback, such as support emails, forms on their website, or dedicated feedback portals.\n",
    "\n",
    "3. **Community Forums**: Participating in community forums, discussion boards, or groups related to the AI product can also be a way to provide feedback and share experiences with other users as well as developers.\n",
    "\n",
    "4. **Surveys and User Studies**: Occasionally, organizations conduct surveys or user studies and invite input on their systems. Participating in these can be a direct way to share your feedback.\n",
    "\n",
    "Giving feedback is crucial because:\n",
    "\n",
    "- **Improvement and Mitigation**: Feedback helps developers identify and prioritize areas that need improvement, particularly regarding bias and other ethical issues.\n",
    "\n",
    "- **User Experience**: User reports can highlight common pain points or issues affecting the experience of the broader user community, leading to targeted enhancements.\n",
    "\n",
    "- **Awareness and Accountability**: Providing feedback raises awareness among developers and stakeholders about specific or systemic issues, encouraging accountability and transparency.\n",
    "\n",
    "Organizations that actively seek and respond to user feedback are typically more effective in addressing and mitigating issues. However, the impact of your feedback can vary depending on the company's commitment to addressing these concerns and their capacity to implement changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398801fc-75b8-4852-9d5f-1405bc7d2196",
   "metadata": {},
   "source": [
    "I found it interesting how honest the LLM was with the concerns I was addressing, and I'm honestly quite surprised that I don't hear more of these concerns as the world becomes more increasingly reliant on AI for many complicated systems such as for criminal justice or healthcare. The LLM brought up many parallels between Unmasking AI and the concers that Buolamwini addresses in her book and they both try to understand the problem by navigating the basis of how these systems came to be which I think is a great question to start with and ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf09c09-8d31-4453-9234-a37e99ec407a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
