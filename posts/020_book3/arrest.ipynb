{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d02693d-5b62-4b65-9acf-2211c0cded60",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"More Unmasking AI: False Arrests\"\n",
    "description: \"facial misclassficiation leads to wrongful conviction\"\n",
    "author: \"Angelica Hu\"\n",
    "date: \"11/12/2025\"\n",
    "categories:\n",
    "- Prompting\n",
    "- LLMs\n",
    "- Living With a Book\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e1f0a-501b-4d96-ac5a-ede657d6b62f",
   "metadata": {},
   "source": [
    "<img src = \"conviction.jpg\" width=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03f1bd-0d9d-432f-9742-79e846a11fa7",
   "metadata": {},
   "source": [
    "As the narrative unfolds, Buolamwini highlights the different ways that the \"encoding bias\" can cause harm within different industries - from healthcare when the system fails to code you into seeking care to false accusations for criminal convictions. Wrongful convictions due to facial misclassification is extremely detrimental as it alters and ruins an innocent individuals life. By introducing this harm, I chose to look a little more in depth into these occurances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d39d79-f557-458f-9183-709418ffb333",
   "metadata": {},
   "source": [
    "In the past, the Biden administration had issued an executive order to set standards and manage the risk of AI in policing. They did so by develping a standard set of “tools, and tests to help ensure that AI systems are safe, secure, and trustworthy.” However, there are still no federal policies in place that regulate the use of AI in this method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b6f7f-46bc-4fd4-a570-eb08ecf09774",
   "metadata": {},
   "source": [
    "A NYT article that discusses \"How the N.Y.P.D.’s Facial Recognition Tool Landed the Wrong Man in Jail\" is a prime example of this. They point out a statistic that nationwide, at least 10 people have been wrongly arrested after being identified with facial recognition technology. \n",
    "\n",
    "\"“We’ve seen this over and over across the country,” said Nathan Wessler of the American Civil Liberties Union. “One of the primary dangers of this technology is that it often gets it wrong.”\" While it is fair to say that facial recognition has helped in solving cases and idetinfying a crmim\n",
    "\n",
    "In Indiana and Detroit, the police are prohibited from putting facial matches in a lineup unless additional evidence — like fingerprints, DNA or cellphone data — connects a suspect to a crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fb4a2-883a-4343-9895-fb2a4a2f20d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
