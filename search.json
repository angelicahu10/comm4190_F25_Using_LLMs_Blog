[
  {
    "objectID": "technical.html",
    "href": "technical.html",
    "title": "1. Text generation",
    "section": "",
    "text": "from openai import OpenAI\nimport os\nimport base64\nimport requests\n\nfrom dotenv import load_dotenv\n# Load API key\n_ = load_dotenv()\ndef encode_image(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\nclient = OpenAI()\n# to get a response must end on a user reponse\nmessages = [\n    {\"role\": \"system\", \n     \"content\": '''\n                   You are a poetic assistant, skilled in explaining complex programming concepts \n                   with creative flair.\n                '''},\n    \n    {\"role\": \"user\", \n     \"content\": '''\n                 Compose a poem that explains why the sky is blue in eight lines.\n                '''}\n     \n  ]\ncompletion = client.chat.completions.create(\n  model=\"gpt-4o\",\n  messages=messages\n)\n\nresponse = completion.choices[0].message.content\nprint(response)\n\nIn daylight's dance, the sky dons hues of blue,  \nAs sunlight weaves through air, a magic true.  \nRayleigh's scattering acts as light's gentle sieve,  \nShort waves of blue, more wily, twist and live.  \n\nThe azure blooms as longer waves drift away,  \nLeaving the sky in a cerulean display.  \nThus, in daylight's tapestry, blue shines with grace,  \nA secret whispered by the sun's embrace."
  },
  {
    "objectID": "technical.html#image-to-text",
    "href": "technical.html#image-to-text",
    "title": "1. Text generation",
    "section": "Image-to-text",
    "text": "Image-to-text\n\n\nimg_path = \"/Commjhub/jupyterhub/home/angelicahu10/comm4190_F25/comm4190_F25_Using_LLMs_Blog/posts/003_professor_image/test_image.jpg\"\nbase64_image = encode_image(img_path)\nprompt = 'Describe this image'\nmax_tokens = 100\n\n\nAs part of the user message you can include the image along with a text prompt to direct how the model should analyze it.\n\n\nmodels = client.models.list()\n\nfor model in models.data:\n    print(model.id)\n\ngpt-4-0613\ngpt-4\ngpt-3.5-turbo\ngpt-audio\ngpt-5-nano\ngpt-audio-2025-08-28\ngpt-realtime\ngpt-realtime-2025-08-28\ndavinci-002\nbabbage-002\ngpt-3.5-turbo-instruct\ngpt-3.5-turbo-instruct-0914\ndall-e-3\ndall-e-2\ngpt-4-1106-preview\ngpt-3.5-turbo-1106\ntts-1-hd\ntts-1-1106\ntts-1-hd-1106\ntext-embedding-3-small\ntext-embedding-3-large\ngpt-4-0125-preview\ngpt-4-turbo-preview\ngpt-3.5-turbo-0125\ngpt-4-turbo\ngpt-4-turbo-2024-04-09\ngpt-4o\ngpt-4o-2024-05-13\ngpt-4o-mini-2024-07-18\ngpt-4o-mini\ngpt-4o-2024-08-06\nchatgpt-4o-latest\no1-mini-2024-09-12\no1-mini\ngpt-4o-realtime-preview-2024-10-01\ngpt-4o-audio-preview-2024-10-01\ngpt-4o-audio-preview\ngpt-4o-realtime-preview\nomni-moderation-latest\nomni-moderation-2024-09-26\ngpt-4o-realtime-preview-2024-12-17\ngpt-4o-audio-preview-2024-12-17\ngpt-4o-mini-realtime-preview-2024-12-17\ngpt-4o-mini-audio-preview-2024-12-17\no1-2024-12-17\no1\ngpt-4o-mini-realtime-preview\ngpt-4o-mini-audio-preview\ncomputer-use-preview\no3-mini\no3-mini-2025-01-31\ngpt-4o-2024-11-20\ncomputer-use-preview-2025-03-11\ngpt-4o-search-preview-2025-03-11\ngpt-4o-search-preview\ngpt-4o-mini-search-preview-2025-03-11\ngpt-4o-mini-search-preview\ngpt-4o-transcribe\ngpt-4o-mini-transcribe\no1-pro-2025-03-19\no1-pro\ngpt-4o-mini-tts\no3-2025-04-16\no4-mini-2025-04-16\no3\no4-mini\ngpt-4.1-2025-04-14\ngpt-4.1\ngpt-4.1-mini-2025-04-14\ngpt-4.1-mini\ngpt-4.1-nano-2025-04-14\ngpt-4.1-nano\ngpt-image-1\ncodex-mini-latest\no3-pro\ngpt-4o-realtime-preview-2025-06-03\ngpt-4o-audio-preview-2025-06-03\no3-pro-2025-06-10\no4-mini-deep-research\no3-deep-research\no3-deep-research-2025-06-26\no4-mini-deep-research-2025-06-26\ngpt-5-chat-latest\ngpt-5-2025-08-07\ngpt-5\ngpt-5-mini-2025-08-07\ngpt-5-mini\ngpt-5-nano-2025-08-07\ngpt-3.5-turbo-16k\ntts-1\nwhisper-1\ntext-embedding-ada-002\n\n\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\"type\": \"text\", \"text\": prompt},\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n              },\n            },\n          ],\n        }\n      ],\n      max_tokens=max_tokens,\n    )\n\n\n---------------------------------------------------------------------------\nBadRequestError                           Traceback (most recent call last)\nCell In[112], line 1\n----&gt; 1 response = client.chat.completions.create(\n      2     model=\"o1\",\n      3     messages=[\n      4         {\n      5           \"role\": \"user\",\n      6           \"content\": [\n      7             {\"type\": \"text\", \"text\": prompt},\n      8             {\n      9               \"type\": \"image_url\",\n     10               \"image_url\": {\n     11                 \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n     12               },\n     13             },\n     14           ],\n     15         }\n     16       ],\n     17       max_tokens=max_tokens,\n     18     )\n\nFile /opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/_utils/_utils.py:279, in required_args.&lt;locals&gt;.inner.&lt;locals&gt;.wrapper(*args, **kwargs)\n    277             msg = f\"Missing required argument: {quote(missing[0])}\"\n    278     raise TypeError(msg)\n--&gt; 279 return func(*args, **kwargs)\n\nFile /opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/resources/chat/completions.py:863, in Completions.create(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\n    821 @required_args([\"messages\", \"model\"], [\"messages\", \"model\", \"stream\"])\n    822 def create(\n    823     self,\n   (...)\n    860     timeout: float | httpx.Timeout | None | NotGiven = NOT_GIVEN,\n    861 ) -&gt; ChatCompletion | Stream[ChatCompletionChunk]:\n    862     validate_response_format(response_format)\n--&gt; 863     return self._post(\n    864         \"/chat/completions\",\n    865         body=maybe_transform(\n    866             {\n    867                 \"messages\": messages,\n    868                 \"model\": model,\n    869                 \"audio\": audio,\n    870                 \"frequency_penalty\": frequency_penalty,\n    871                 \"function_call\": function_call,\n    872                 \"functions\": functions,\n    873                 \"logit_bias\": logit_bias,\n    874                 \"logprobs\": logprobs,\n    875                 \"max_completion_tokens\": max_completion_tokens,\n    876                 \"max_tokens\": max_tokens,\n    877                 \"metadata\": metadata,\n    878                 \"modalities\": modalities,\n    879                 \"n\": n,\n    880                 \"parallel_tool_calls\": parallel_tool_calls,\n    881                 \"prediction\": prediction,\n    882                 \"presence_penalty\": presence_penalty,\n    883                 \"reasoning_effort\": reasoning_effort,\n    884                 \"response_format\": response_format,\n    885                 \"seed\": seed,\n    886                 \"service_tier\": service_tier,\n    887                 \"stop\": stop,\n    888                 \"store\": store,\n    889                 \"stream\": stream,\n    890                 \"stream_options\": stream_options,\n    891                 \"temperature\": temperature,\n    892                 \"tool_choice\": tool_choice,\n    893                 \"tools\": tools,\n    894                 \"top_logprobs\": top_logprobs,\n    895                 \"top_p\": top_p,\n    896                 \"user\": user,\n    897             },\n    898             completion_create_params.CompletionCreateParams,\n    899         ),\n    900         options=make_request_options(\n    901             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n    902         ),\n    903         cast_to=ChatCompletion,\n    904         stream=stream or False,\n    905         stream_cls=Stream[ChatCompletionChunk],\n    906     )\n\nFile /opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/_base_client.py:1290, in SyncAPIClient.post(self, path, cast_to, body, options, files, stream, stream_cls)\n   1276 def post(\n   1277     self,\n   1278     path: str,\n   (...)\n   1285     stream_cls: type[_StreamT] | None = None,\n   1286 ) -&gt; ResponseT | _StreamT:\n   1287     opts = FinalRequestOptions.construct(\n   1288         method=\"post\", url=path, json_data=body, files=to_httpx_files(files), **options\n   1289     )\n-&gt; 1290     return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n\nFile /opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/_base_client.py:967, in SyncAPIClient.request(self, cast_to, options, remaining_retries, stream, stream_cls)\n    964 else:\n    965     retries_taken = 0\n--&gt; 967 return self._request(\n    968     cast_to=cast_to,\n    969     options=options,\n    970     stream=stream,\n    971     stream_cls=stream_cls,\n    972     retries_taken=retries_taken,\n    973 )\n\nFile /opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/_base_client.py:1071, in SyncAPIClient._request(self, cast_to, options, retries_taken, stream, stream_cls)\n   1068         err.response.read()\n   1070     log.debug(\"Re-raising status error\")\n-&gt; 1071     raise self._make_status_error_from_response(err.response) from None\n   1073 return self._process_response(\n   1074     cast_to=cast_to,\n   1075     options=options,\n   (...)\n   1079     retries_taken=retries_taken,\n   1080 )\n\nBadRequestError: Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}\n\n\n\n\nThe response object contains a lot of information returned by the API call\n\n\nresponse\n\nChatCompletion(id='chatcmpl-CDwAqoQDkta7HqdsyDO6o36984aYB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The image shows a person wearing a neck brace and looking at the camera. They have some visible injuries on their face, including cuts and bruises. Their right hand is bandaged, and they are holding it up with three fingers extended. The background appears to be indoors with a door and some light coming through.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1757437920, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_cbf1785567', usage=CompletionUsage(completion_tokens=63, prompt_tokens=775, total_tokens=838, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n\n\n\nYou can pick out just the message\n\n\nprint(response.choices[0].message.content)\n\nThe image shows a person wearing a neck brace and looking at the camera. They have some visible injuries on their face, including cuts and bruises. Their right hand is bandaged, and they are holding it up with three fingers extended. The background appears to be indoors with a door and some light coming through."
  },
  {
    "objectID": "technical.html#text-to-image",
    "href": "technical.html#text-to-image",
    "title": "1. Text generation",
    "section": "Text to image",
    "text": "Text to image\n\nVarious models will also generate an image based on a text description passed in the API call\n\n\nimage_prompt1 = '''\n            create an image of a man holding his hand up'''\n\n\n\n\nresponse = client.images.generate(\n  model=\"dall-e-3\",\n  prompt=image_prompt1,\n  size=\"1024x1024\",\n  quality=\"standard\",\n  n=1,\n)\n\nimage_url = response.data[0].url\n\n\nThe generated image will be temporary available on a cloud server\n\n\nimage_url\n\n'https://oaidalleapiprodscus.blob.core.windows.net/private/org-OGTziyXQKv8dkYauRD1K0Osu/user-jPwUdbyoM52WOxjQGrtmBHI6/img-PIHE3jWQagNqeNkB0RO91xNW.png?st=2025-09-09T16%3A12%3A46Z&se=2025-09-09T18%3A12%3A46Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=52f8f7b3-ca8d-4b21-9807-8b9df114d84c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-09-09T17%3A12%3A46Z&ske=2025-09-10T17%3A12%3A46Z&sks=b&skv=2024-08-04&sig=D8wVb5cXDk9%2Bptx0fCRrDbMj3B/aJNGZnRvN9zdeohs%3D'\n\n\n\nBut most often you will want to download it as part of your script\n\n\ngenerated_image = requests.get(image_url)\n\nwith open('generated_img.png', 'wb') as out:\n    out.write(generated_image.content)"
  },
  {
    "objectID": "posts/002_wolfram_article/wolfram.html",
    "href": "posts/002_wolfram_article/wolfram.html",
    "title": "The Wolfram Article",
    "section": "",
    "text": "The way that LLMs basically create output is with “reasonable continuation,” looking at the response with the highest probability. I think it’s super interesting to learn that ChatGpt or other models are basically just making their best guesses at what makes sense, using lots of randomness to come up with non-flat responses. There’s an infinite combination of possible sequences with no correct answer. It was super cool to see how the next word that is outputted is based on the previous word, which then becomes sequences. I found it much easier to understand this complex process when breaking it down from letters, to words, to sentences.\n\nI tried to follow the coding in my Jupyter notebook but learned that the code in the article followed Mathematica/Wolfram syntax instead of Python syntax. I’m interested to learn what differentiates the two, and how to convert them to work with certin models.\nI was also surprised to learn that there are 40,000 reasonably common words in English. While I know English is a vast language, I had never given it much thought how many words I typically use on a daily basis or the words used in conversation!"
  },
  {
    "objectID": "posts/002_wolfram_article/wolfram.html#section",
    "href": "posts/002_wolfram_article/wolfram.html#section",
    "title": "The Wolfram Article",
    "section": "",
    "text": "The way that LLMs basically create output is with “reasonable continuation,” looking at the response with the highest probability. I think it’s super interesting to learn that ChatGpt or other models are basically just making their best guesses at what makes sense, using lots of randomness to come up with non-flat responses. There’s an infinite combination of possible sequences with no correct answer. It was super cool to see how the next word that is outputted is based on the previous word, which then becomes sequences. I found it much easier to understand this complex process when breaking it down from letters, to words, to sentences.\n\nI tried to follow the coding in my Jupyter notebook but learned that the code in the article followed Mathematica/Wolfram syntax instead of Python syntax. I’m interested to learn what differentiates the two, and how to convert them to work with certin models.\nI was also surprised to learn that there are 40,000 reasonably common words in English. While I know English is a vast language, I had never given it much thought how many words I typically use on a daily basis or the words used in conversation!"
  },
  {
    "objectID": "posts/007_swimming/llm_swim.html",
    "href": "posts/007_swimming/llm_swim.html",
    "title": "Can LLM’s Swim",
    "section": "",
    "text": "As I mentioned earlier, swimming has always been a passion of mine! Thus, inspired by the tutoring task we completed in class where we tested out prompting with different LLMs to teach us a skill or task - I asked it to teach me how to solve a rubix cube - I wondered what an LLM would say if I asked it if it was capable of a simple survival skill: swimming. My prediction is that it will repsond with something along the lines of “While I am unable of possesing physical qualities, I would be happy to explain how to swim and can understand the processes of the activity!” Something like that.\nFor this blog entry, I am going to experiment with 4 different LLM’s and have them compete to see who is the fastest swimmer! Almost as if its a virtual swim meet among different LLMs! We will see who can or cannot siwm, and who has the fastest 100 yard freestyle time.\nFor reference, my time is around 54.6 seconds and I have been swimming for over 13 years."
  },
  {
    "objectID": "posts/007_swimming/llm_swim.html#conclusion-1",
    "href": "posts/007_swimming/llm_swim.html#conclusion-1",
    "title": "Can LLM’s Swim",
    "section": "Conclusion 1",
    "text": "Conclusion 1\nAs you can tell, the prompts I was providing didn’t give me the results I was expecting starting with the first LLM, although I did accurately predict it’s response to its ability to swim. Let’s try this again…"
  },
  {
    "objectID": "posts/007_swimming/llm_swim.html#conclusion-2",
    "href": "posts/007_swimming/llm_swim.html#conclusion-2",
    "title": "Can LLM’s Swim",
    "section": "Conclusion 2",
    "text": "Conclusion 2\nNot surprisingly, all three LLMs responded to the first question in a similar manner in that swimming was out of their physical capabilities. However, when asked to be a pretend swimmer, it looks like gpt4.0 was the fastest, then gemini 2.5, and finally claude 3.5. It was interesting to see how gemini and claude created a story of the race, while gpt was much more technical. Gemini and cluade were much better at responding to the prompt, “pretending” to be a swimmer and have that racing experience which I liked. As for the times, I would say that claude 3.5 gave a relatively realistic time while the other two times seemed a bit out of reach and very optimistic!"
  },
  {
    "objectID": "posts/004_origins_ChatGPT/origins_ChatGPT.html#video-notes",
    "href": "posts/004_origins_ChatGPT/origins_ChatGPT.html#video-notes",
    "title": "The Birth of ChatGPT",
    "section": "Video Notes",
    "text": "Video Notes\n\nsiloed networks model intuition only, not reasoning -&gt; must train machines to talk\nlearned sequences were generalized\nsystem spatially organizes words based on meaning of words\nfeeding the output back into the input with a short prompt, following a pathway of thought\nrecurrent neural networks that become much larger systems to increase percision and predictability\ntransformers = takes context around it to change its meanings\nzero shot learning\nmaking the network contiues to make it speak less giberrish and increased performance\nin context learning\ncore in weight learning = during training\nin context learning = in use or inference\nLLMs should not be considered a chatbot or word generator, rtaher a kernal process of an operating system\nneural networks allow deep learning and for AI to make connections and draw predictions\n\n\nfrom openai import OpenAI\nimport os\nimport base64\nimport requests\n\nfrom dotenv import load_dotenv\n# Load API key\n_ = load_dotenv()\n\n\ndef encode_image(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\n\n\n client = OpenAI()\n\n\nprompt1 = '''\n\nTell me about how you were created, or the origins of ChatGPT!\n\n'''\n\nprompt2 = '''\n\nTell me about how you were created, or the origins of ChatGPT in simple terms, to someone who is not familar with technical terms.\n\n'''\n\n\n messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful assistant.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt\n            }\n        ]\n\n\ndef generate_story(prompt1, model=\"gpt-4o\"):\n\n    completion = client.chat.completions.create(\n      model=model,\n      messages=[\n        {\"role\": \"system\", \n         \"content\": \"You are a helpful AI assistant.\"},\n        {\"role\": \"user\", \n         \"content\": prompt1}\n      ]\n    )\n    \n    response = completion.choices[0].message.content\n    return response\n\n\ngenerate_story(prompt1, model=\"gpt-4o\")\n\n'ChatGPT, like many AI language models, is based on the GPT (Generative Pre-trained Transformer) architecture, developed by OpenAI. The creation of GPT models involves several key components and milestones:\\n\\n1. **Transformer Architecture**: The foundation of GPT models is the transformer architecture, which was introduced in the 2017 paper \"Attention is All You Need\" by Vaswani et al. This architecture uses attention mechanisms that allow the model to weigh the importance of different words in a sentence when making predictions, which enables more efficient processing of large datasets and capture of contextual relationships.\\n\\n2. **Pre-training and Fine-tuning**: GPT models are developed through a two-step process: pre-training and fine-tuning. In the pre-training phase, the model is trained on a large corpus of text from the internet to predict the next word in a sentence, learning grammar, facts about the world, and some reasoning abilities. During fine-tuning, the model is adjusted for specific tasks (e.g., conversation), using a narrower dataset with human annotations to align the model’s behavior with specific goals.\\n\\n3. **GPT Series**: The evolution of GPT models began with GPT-1, released in 2018, which had 117 million parameters. OpenAI then released GPT-2 in 2019, notable for its size (1.5 billion parameters) and improved language understanding capabilities. GPT-3 followed in 2020, making a significant leap with 175 billion parameters, allowing for even more nuanced text generation and greater performance across a range of tasks.\\n\\n4. **ChatGPT**: Building on the advances of GPT-3 and its predecessors, ChatGPT was developed to generate interactive, conversational text. OpenAI applied reinforcement learning from human feedback (RLHF) to improve the model\\'s ability to follow instructions and provide meaningful, context-rich responses in a conversational format.\\n\\n5. **Iterative Improvements and Public Use**: OpenAI has continued to iterate on GPT models, incorporating feedback from public use to improve safety, reduce bias, and enhance capabilities. Subsequent updates and versions have further refined the system’s performance and user experience.\\n\\nOverall, the creation of ChatGPT involved advances in machine learning, natural language processing, and AI ethics, with the aim of building powerful and adaptable language models for various applications.'\n\n\n\n messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful assistant.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt2\n            }\n        ]\n\n\ndef generate_story(prompt2, model=\"gpt-4o\"):\n\n    completion = client.chat.completions.create(\n      model=model,\n      messages=[\n        {\"role\": \"system\", \n         \"content\": \"You are a helpful AI assistant.\"},\n        {\"role\": \"user\", \n         \"content\": prompt2}\n      ]\n    )\n    \n    response = completion.choices[0].message.content\n    return response\n\n\ngenerate_story(prompt2, model=\"gpt-4o\")\n\n'Sure! ChatGPT is a type of computer program designed to have conversations with people, like a virtual assistant.\\n\\nThe origins of ChatGPT can be traced back to the development of AI, or artificial intelligence, which is the idea of creating machines that can perform tasks that usually require human intelligence. To make ChatGPT, researchers and engineers used advanced technology and a lot of data to teach the program how to understand and respond to human language.\\n\\nThey created a special kind of program called a \"language model.\" This model was trained on a vast amount of text—from books, websites, and other sources—so it could learn how people use language. In simple terms, it learned from examples of human language how to predict and generate text that makes sense in a conversation.\\n\\nThe goal was to create a helpful tool that could understand questions and provide useful answers, like having a conversation with a knowledgeable friend. Over time, the technology has improved, making ChatGPT better at understanding context and providing more accurate responses.\\n\\nThe team behind ChatGPT is continually working on refining and improving it, so it gets better at helping people with their questions and needs over time.'"
  },
  {
    "objectID": "troubleshoot.html",
    "href": "troubleshoot.html",
    "title": "My Explorations With LLMs",
    "section": "",
    "text": "!grep -Rn --include=\"*.qmd\" \"about:\" .\n\n./.ipynb_checkpoints/about-checkpoint.qmd:4:about:\n./about.qmd:4:about:\n\n\n\n!nl -ba about.qmd | sed -n '1,40p'\n!nl -ba ./.ipynb_checkpoints/about-checkpoint.qmd | sed -n '1,40p'\n\n     1  ---\n     2  title: \"About\"\n     3  image: profile.jpg\n     4  about:\n     5    template: jolla\n     6  ---\n     7  \n     8  Hi! My name is Angelica and I'm a current sophomore at the University of Pennsylvania studying Health & Societies, concentrating in Healthcare Markets and Finance. I'm also minoring in Neuroscience & Healthcare Management, and Data Science and Analytics.\n     9  \n    10  Angelica Hu\n     1  ---\n     2  title: About\n     3  image: profile.jpg\n     4  about:\n     5    template: jolla\n     6  ---\n     7  \n     8  About this blog\n\n\n\n!rm -rf ./.ipynb_checkpoints\n\n\n!printf \".ipynb_checkpoints/\\n\" &gt; .quartoignore\n!printf \"\\n.ipynb_checkpoints/\\n\" &gt;&gt; .gitignore\n\n\n!rm -rf ./_site\n!rm -rf ./.quarto\n\n\n!grep -Rn --include=\"*.qmd\" --include=\"*.yml\" --include=\"*.yaml\" '^about:\\s\\S' . || true\n\n\n!grep -RnP '\\t' --include=\"*.qmd\" --include=\"*.yml\" --include=\"*.yaml\" . || true\n\n\n!git add -A\n!git commit -m \"Clean checkpoints, ignore them; clear Quarto cache; confirm about: mapping\"\n!git push\n\n[main 67675f1] Clean checkpoints, ignore them; clear Quarto cache; confirm about: mapping\n 4 files changed, 58 insertions(+), 1 deletion(-)\n create mode 100644 .quartoignore\n create mode 100644 troubleshoot.ipynb\nEnumerating objects: 9, done.\nCounting objects: 100% (9/9), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (5/5), done.\nWriting objects: 100% (6/6), 1.04 KiB | 355.00 KiB/s, done.\nTotal 6 (delta 3), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (3/3), completed with 3 local objects.\nTo https://github.com/angelicahu10/comm4190_F25_Using_LLMs_Blog.git\n   17eeece..67675f1  main -&gt; main"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! My name is Angelica and I’m a current sophomore at the University of Pennsylvania studying Health & Societies, concentrating in Healthcare Markets and Finance. I’m also minoring in Neuroscience & Healthcare Management, and Data Science and Analytics.\nAngelica Hu"
  },
  {
    "objectID": "posts/001_first_post/personal_info.html",
    "href": "posts/001_first_post/personal_info.html",
    "title": "My First Blog Post!",
    "section": "",
    "text": "Hello! My name is Angelica and this first blog post is going to be getting to know a little bit about me while I explore how to use this platform! My experience with data science/coding comes from PHYS1100: Foundations of Data Science, which I took last semester as well as some other coding experience I did in high school."
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#hello",
    "href": "posts/001_first_post/personal_info.html#hello",
    "title": "My First Blog Post!",
    "section": "",
    "text": "Hello! My name is Angelica and this first blog post is going to be getting to know a little bit about me while I explore how to use this platform! My experience with data science/coding comes from PHYS1100: Foundations of Data Science, which I took last semester as well as some other coding experience I did in high school."
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#my-family",
    "href": "posts/001_first_post/personal_info.html#my-family",
    "title": "My First Blog Post!",
    "section": "My Family",
    "text": "My Family\nMy parents are from China, but me and my two older sisters were born here which makes us second generation. My older sisters both live in New York City now after graduating from college. This photo is from June from my middle sister’s college graduation in Evanston, Illinois. I loveee Chicago!\nWe also have a dog named Minnie! She’s a goldendoodle and turning 11 this year. I miss her a lot!"
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#academics",
    "href": "posts/001_first_post/personal_info.html#academics",
    "title": "My First Blog Post!",
    "section": "Academics",
    "text": "Academics\nHere at Penn, I’m studying Health and Societies with a concentration in Healthcare Markets and Finance and a minor in Data Science and Analytics. I hope to explore the healthcare system and work towards fixing health disparities and improve access and quality, perhaps through healthcare data analytics!"
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#interests",
    "href": "posts/001_first_post/personal_info.html#interests",
    "title": "My First Blog Post!",
    "section": "Interests",
    "text": "Interests\nI love competitive swimming as I’ve swam my whole life. I also am a big foodie and love trying new resturants! My favorite shows are Friends, How I Met Your Mother, funny sit coms like that. I’m super excited to learm more about LLMs and AI in this class!\n\n(me when i understand how to use github and face no technical difficulties)"
  },
  {
    "objectID": "posts/005_unmasking_AI/book_assignment.html",
    "href": "posts/005_unmasking_AI/book_assignment.html",
    "title": "Unmasking: Unmasking AI",
    "section": "",
    "text": "Thus far in the semester for this course, I have read a decent amount of Buolamwini’s Unmasking Ai Narrative. My initial thoughts were very intriguing since the idea that technology or artificial intellegence could have potential racial biases was one that never crossed my mine - perhaps that is because I am in a privilged position where I have personally never experienced any conflicts with it. However, that doesn’t imply that it is a problem in today’s society which Joy Buolmwini touches upon her personal experiences with facial recognition as a woman of color in this novel.\nWhat I appreicate about her writing style is it’s narrative stucture and personability as she discusses how she started to study this phenomenon of ‘the coded gaze’ based on her background and throughout her education as a student. While I’m still in the beginning of the novel, when thing I do notice which I may not be the biggest fan of is how repetitive much of the content feels. It is important for Buolamwini to describe the problems she’s facing with the software, but when she constantly emphasizes it over and over, the line loses its significance in a way and almost becomes too victimazing. However, the points she brings up make me question why people who were initally building these kinds of softwares didn’t consider these biases and issues of representation in the first place. Is it because they didn’t matter as much during that time? Or a systemic issue? She mentiones that the idea of artificial intellegence was introduced in 1956 - so within roughly 69 years that its been able to develop, I think ideas regarding racial equality have significantly mattered more with the modern age and society.\nI wonder what some LLMs think about whether or not there are issues wiht racial biases in artifical intellegence and what they have to say about themselves… Here’s what gpt4.0 had to say:\n\nUSER\nDo you think artificial intelligence softwares, such as facial recognition, contain racial biases and may not be fully representative of all types of people?\n\n\nASSISTANT\nYes, there is substantial evidence suggesting that some artificial intelligence (AI) systems, including facial recognition software, can exhibit racial biases and may not perform equally well for all demographic groups. Several studies have highlighted disparities in the accuracy of facial recognition systems, particularly across different races, genders, and age groups. For instance, research has shown that these systems often have higher error rates for people with darker skin tones and for women, which can lead to misidentifications and unfair outcomes.\nThese biases can stem from several factors:\n\nTraining Data: AI models are trained on large datasets that may not be representative of the full diversity of human faces. If a dataset is imbalanced—overrepresenting certain demographics while underrepresenting others—the model is more likely to perform poorly on underrepresented groups.\nAlgorithm Design: The algorithms themselves can introduce or exacerbate biases, especially if they are not explicitly designed to account for demographic diversity.\nSystem Evaluation: The lack of thorough testing across diverse demographic groups can result in insufficient understanding of the system’s performance across those groups.\n\nTo address these issues, it is crucial for developers to use diverse and representative datasets, implement fairness checks during the design process, regularly evaluate system performance across different demographics, and work towards transparency and accountability in AI systems. This can help mitigate biases and improve fairness and accuracy for all users.\n\n\nUSER\nWhy hasn’t this been a big issue of research in the public news? Are people actively taking steps to help solve this as the world becomes more increasingly AI focused?\n\n\nASSISTANT\nThe issue of bias in AI, particularly in technologies such as facial recognition, has increasingly become a topic of public research and media attention over the past several years. There are a few reasons why this topic may not have been front and center in public discourse until more recently:\n\nAwareness and Understanding: Initially, there was a general lack of awareness and understanding of how AI systems work and the potential for bias within them. As awareness has grown, so has the attention paid to these issues.\nComplexity of the Issue: The technical nature of AI and machine learning can make it difficult for the general public to engage with the specifics of algorithmic bias, which can limit broader discourse.\nEmergence of High-Profile Studies and Incidents: Media attention has increased in response to high-profile studies and incidents that highlight the real-world consequences of biased AI systems, such as cases of wrongful arrests due to misidentifications by facial recognition.\nAdvocacy and Regulation: Advocacy groups and researchers have worked to raise awareness about the ethical implications of biased AI, leading to an increase in public and academic discussions, as well as policy considerations.\nRegulatory Developments: Governments and regulatory bodies around the world are becoming more attuned to the necessity of ensuring AI deployments are fair and equitable. This includes efforts to introduce regulations and guidelines that aim to mitigate bias and protect privacy.\nCorporate Responsiveness: Some technology companies are taking proactive measures to address bias in AI systems, such as diversifying training datasets, implementing fairness audits, and developing bias detection tools.\nCommunity and NGO Involvement: Non-governmental organizations and community groups have become vocal, ensuring that issues related to AI bias are addressed, especially when they impact marginalized groups.\n\nOverall, while more work is needed to ensure fair and equitable AI systems, there is growing recognition of these issues in both technical research and public discourse. This increase in attention is contributing to more focused research and policy initiatives aimed at reducing bias in AI technologies.\n\n\nUSER\nDo you believe this is a pressing concern?\n\n\nASSISTANT\nYes, addressing bias in AI systems is a pressing concern. As AI technologies become more integrated into various aspects of everyday life—including law enforcement, hiring, healthcare, and financial services—the potential for biased systems to lead to unjust outcomes becomes more significant. Some key reasons why this is a critical issue include:\n\nSocial Impact: Biased AI systems can perpetuate or even exacerbate existing social inequalities and discrimination. For example, inaccuracies in facial recognition could lead to biased surveillance practices, while biased hiring algorithms could perpetuate workplace inequality.\nTrust and Adoption: Trust in AI technologies is essential for their widespread adoption. If people believe these systems are biased or unfair, it can undermine public confidence and hinder the beneficial application of AI.\nLegal and Ethical Implications: There are significant legal and ethical considerations around the deployment of biased AI systems. Organizations need to ensure compliance with regulations and ethical standards to avoid legal challenges and protect individual rights.\nAccountability and Transparency: As AI systems make decisions that can affect people’s lives, it’s crucial to ensure these systems are transparent and accountable. Addressing bias is a key part of this, as it involves making AI systems understandable and justifiable to the people impacted by their decisions.\nLong-term Effects: The longer biased systems remain unaddressed, the more likely it is that they will lead to systemic issues, reinforcing biases and making it harder to correct them in the future.\n\nEfforts to tackle these challenges are ongoing, with researchers, policymakers, and organizations all contributing to developing solutions. These efforts include creating more representative datasets, developing algorithms that are robust to bias, setting industry standards, and establishing regulatory frameworks aimed at ensuring fairness and accountability in AI systems. Overall, addressing bias in AI is essential to harness the technology’s full potential for positive social impact.\n\n\nUSER\nSo you can verify that you may have racial biases…\n\n\nASSISTANT\nAs an AI language model, I don’t possess personal beliefs or the ability to experience bias in the way humans do. However, it is true that I am trained on vast datasets derived from internet sources, including a wide array of human communications. These datasets can potentially contain biased or unbalanced information, which means that biases present in the data can sometimes be reflected in the model’s outputs.\nEfforts are made to minimize these biases during the training and development of AI models, but it’s a complex challenge and not entirely resolvable due to the nature of the data. Researchers and developers work continuously to identify and mitigate biases to improve fairness and accuracy.\nIf you notice any biased or inappropriate outputs, it’s important to provide feedback, as this helps improve the system over time. Ensuring AI systems are fair and equitable remains an ongoing process, requiring constant attention and improvement.\n\n\nUSER\nI think I sense some biases, where do I report feedback and does it actually matter?\n\n\nASSISTANT\nIf you encounter biases or other issues in AI outputs, providing feedback is an important step in helping improve the systems. The process and effectiveness of reporting feedback can vary depending on the platform or organization managing the AI model. Here are some general steps you can take:\n\nPlatform-Specific Feedback Channels: Many platforms have built-in feedback mechanisms where users can report issues. Look for a feedback option in the app or website where you’re interacting with the AI.\nOfficial Channels: Some organizations provide dedicated channels for feedback, such as support emails, forms on their website, or dedicated feedback portals.\nCommunity Forums: Participating in community forums, discussion boards, or groups related to the AI product can also be a way to provide feedback and share experiences with other users as well as developers.\nSurveys and User Studies: Occasionally, organizations conduct surveys or user studies and invite input on their systems. Participating in these can be a direct way to share your feedback.\n\nGiving feedback is crucial because:\n\nImprovement and Mitigation: Feedback helps developers identify and prioritize areas that need improvement, particularly regarding bias and other ethical issues.\nUser Experience: User reports can highlight common pain points or issues affecting the experience of the broader user community, leading to targeted enhancements.\nAwareness and Accountability: Providing feedback raises awareness among developers and stakeholders about specific or systemic issues, encouraging accountability and transparency.\n\nOrganizations that actively seek and respond to user feedback are typically more effective in addressing and mitigating issues. However, the impact of your feedback can vary depending on the company’s commitment to addressing these concerns and their capacity to implement changes.\nI found it interesting how honest the LLM was with the concerns I was addressing, and I’m honestly quite surprised that I don’t hear more of these concerns as the world becomes more increasingly reliant on AI for many complicated systems such as for criminal justice or healthcare. The LLM brought up many parallels between Unmasking AI and the concers that Buolamwini addresses in her book and they both try to understand the problem by navigating the basis of how these systems came to be which I think is a great question to start with and ask."
  },
  {
    "objectID": "posts/006_collegeadvice/college.html",
    "href": "posts/006_collegeadvice/college.html",
    "title": "How Do I Get Into College?",
    "section": "",
    "text": "I can still remember being a Senior in high school, stressing about the complex college application process. That summer going into the last year was spent brainstorming ideas for the common application essay. Knowing that you could write about anything almost made it even harder to hone down on one topic. Thus, I decided to play around and see how an LLM (anthropic/claude-3.5-sonnet) could help make this process a little easier, helping to brainstorm potential prompts and create a college list as well. It’s almost like it is a private $100,000 college counseler. I played around and tried my best to give clear directions and prompts to optimize the LLM’s output according to the PEGAI reading on Chapter 3.\n\n\n\nPretend you are a college counselor. I want help compiling a college list and come up with an idea for the common application essay. Generate a bullet-point list of 10 colleges/universities in the United States with their acceptance rate and a 5 bullet-point list of potential college essay topics.\n\n\n\n\n\nAs a college counselor, I’ll help you with a college list and essay topics. However, to provide more personalized recommendations, it would be helpful to know your: - Academic interests/intended major - GPA and test scores - Geographic preferences - Financial considerations - Extracurricular activities\n\n\nNevertheless, here’s a diverse list of colleges with varying selectivity:\n\n\nColleges/Universities: • Stanford University (CA) - 4% acceptance rate • University of Michigan (MI) - 20% acceptance rate • Boston University (MA) - 14% acceptance rate • University of Wisconsin-Madison (WI) - 60% acceptance rate • Northeastern University (MA) - 18% acceptance rate • University of Texas at Austin (TX) - 32% acceptance rate • University of Virginia (VA) - 21% acceptance rate • Purdue University (IN) - 60% acceptance rate • New York University (NY) - 12% acceptance rate • University of Washington (WA) - 56% acceptance rate\n\n\nPotential Essay Topics: • A significant challenge you’ve overcome and how it shaped your character • An experience that sparked your intellectual curiosity or passion for learning • A meaningful community service project or leadership experience • A cultural tradition or family value that has influenced your worldview • A moment of failure that led to personal growth and self-discovery\n\n\nWould you like to share more about your background so I can provide more tailored suggestions?\n\n\n\n\n\nI don’t feel comfortable providing personal information.\n\n\n\n\n\nI completely understand and respect your privacy. The college list I provided includes a good mix of: - Large research universities - Urban and suburban locations - Different geographic regions - Varying acceptance rates (from highly selective to more accessible) - Both private and public institutions\n\n\nFor the essay topics, here’s some additional context on why these topics work well:\n\n\n\n“A significant challenge you’ve overcome”\n\n\nShows resilience\nDemonstrates personal growth\nReveals character and determination\n\n\n\n\n“An experience that sparked intellectual curiosity”\n\n\nShows genuine interest in learning\nReveals your academic passions\nDemonstrates intellectual vitality\n\n\n\n\n“A meaningful community service/leadership experience”\n\n\nShows initiative\nDemonstrates impact on others\nReveals values and priorities\n\n\n\n\n“A cultural tradition/family value”\n\n\nShows self-awareness\nReveals personal background\nDemonstrates understanding of influences\n\n\n\n\n“A moment of failure”\n\n\nShows humility\nDemonstrates ability to learn from mistakes\nReveals maturity and self-reflection\n\n\n\nRemember that the best essays are: - Personal and specific - Show rather than tell - Authentic to your voice - Reveal something not found elsewhere in your application - Well-written but not overly formal\n\n\nWould you like me to elaborate on any of these points?\n\n\n\n\n\nPlease provide specific topics instead of essay question ideas. See an example below: * a sports injury that caused an athlete to quit their sport\n\n\n\na job that a student loves and how it’s influenced them\n\n\n\n\na student’s background and culture and how that shapes their identity\n\n\n\n\nan extended metaphor about the letter ‘s’\n\n\n\n\n\n\nHere are 10 specific essay topics:\n\n\n\nHow learning to cook my grandmother’s traditional dumplings connected me to my Chinese heritage and taught me patience\n\n\n\n\nMy experience running the school’s Instagram account transformed my understanding of digital storytelling and community building\n\n\n\n\nAn extended metaphor comparing my life journey to tending my rooftop garden - from planting seeds to weathering storms\n\n\n\n\nHow my part-time job at a local bookstore sparked my love for recommending books and connecting with strangers through literature\n\n\n\n\nThe day my stutter became my superpower: finding confidence through speech therapy and public speaking\n\n\n\n\nAn extended metaphor comparing my collection of mismatched socks to embracing life’s imperfections\n\n\n\n\nHow teaching my elderly neighbor to use Zoom during the pandemic evolved into a meaningful intergenerational friendship\n\n\n\n\nMy journey from being the only girl on the robotics team to becoming team captain and mentoring other young women in STEM\n\n\n\n\nHow my daily bus commute through different neighborhoods opened my eyes to social inequality and inspired my interest in urban planning\n\n\n\n\nThe story of three family photographs: exploring how my relationship with my adopted sister evolved over time\n\n\n\nEach of these topics is: - Specific and personal - Shows character development - Has potential for vivid storytelling - Reveals something meaningful about the writer - Can be developed into a compelling narrative\n\n\n\n\nIt’s interesting to see the output that the LLM provides given no prior knowledge about who I am as a person. It was interesting to see how there wasn’t mention about athletics, the arts, or other hobbys."
  },
  {
    "objectID": "posts/006_collegeadvice/college.html#conclusions",
    "href": "posts/006_collegeadvice/college.html#conclusions",
    "title": "How Do I Get Into College?",
    "section": "",
    "text": "It’s interesting to see the output that the LLM provides given no prior knowledge about who I am as a person. It was interesting to see how there wasn’t mention about athletics, the arts, or other hobbys."
  },
  {
    "objectID": "posts/003_professor_image/odonnell.html",
    "href": "posts/003_professor_image/odonnell.html",
    "title": "Testing Image Analysis",
    "section": "",
    "text": "I hope you are feeling better Professor O’Donnell when you read this and are recovering well! I tried some different prompts running the below pic which was provided on Canvas through the image-to-text API call in Jupyterhub. I was surprised to find some of the different responses that were output depending on which model the image was run through."
  },
  {
    "objectID": "posts/003_professor_image/odonnell.html#the-prompt-describe-this-image.",
    "href": "posts/003_professor_image/odonnell.html#the-prompt-describe-this-image.",
    "title": "Testing Image Analysis",
    "section": "The Prompt: “Describe this image.”",
    "text": "The Prompt: “Describe this image.”\n\nResponses:\n\ngpt 4.0: “The image shows a person wearing a neck brace and looking at the camera. They have some visible injuries on their face, including cuts and bruises. Their right hand is bandaged, and they are holding it up with three fingers extended. The background appears to be indoors with a door and some light coming through.”\nanthropic/claude-3.5-sonnet: “This appears to be a selfie taken from a low angle, showing someone wearing what looks like a VR headset or similar head-mounted device. The person is wearing a light-colored shirt and appears to have some substance or marks on their face. There’s also what appears to be a hand with a cloth or towel visible in the upper right corner of the image. The photo seems to be taken indoors, with a light-colored wall or ceiling visible in the background.”\nGoogle: Gemini 2.5 Flash: “This image is a close-up, selfie-style portrait of an adult male who appears to have recently sustained injuries. The man is looking directly at the camera with a neutral expression. His face shows several signs of injury: there are visible scrapes and scabs on his forehead, particularly above his left eyebrow. His nose has noticeable bruising and scabbing. His lips appear swollen, and there are dark scabs or stitches visible on his lower lip and chin area. He is wearing a white and grey cervical collar or neck brace around his neck. His right hand is raised into the upper right portion of the frame, and it is wrapped in a white, textured bandage or gauze, with his fingers slightly spread. He is wearing a light pink t-shirt, and a dark green design resembling pine trees is visible on the lower left side of the shirt. The background is an indoor setting with light-colored (beige/off-white) walls. To the right, part of a white door frame and a window are visible, through which bright natural light is entering. A small, light-colored sensor is attached to the top of the door frame. The ceiling is also visible at the top of the frame.”"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Blog!",
    "section": "",
    "text": "Can LLM’s Swim\n\n\n\nLLMs\n\nPrompting\n\nComparison\n\n\n\nWho’s?\n\n\n\n\n\nOct 20, 2025\n\n\nAngelica Hu\n\n\n\n\n\n\n\n\n\n\n\n\nHow Do I Get Into College?\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\nCollege\n\n\n\nmaking a college list + brainstorming essay topics\n\n\n\n\n\nSep 21, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nUnmasking: Unmasking AI\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n[object Object]\n\n\n\nInside Joy Buolamwini’s Great Mind\n\n\n\n\n\nSep 18, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nThe Birth of ChatGPT\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nHow did we get here?\n\n\n\n\n\nSep 15, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Image Analysis\n\n\n\nLLMs\n\nPrompting\n\n\n\nFeel Better Professor O’Donnell!\n\n\n\n\n\nSep 9, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nMy First Blog Post!\n\n\n\nMy Profile\n\n\n\nGet to Know Me\n\n\n\n\n\nSep 3, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nThe Wolfram Article\n\n\n\nLLMs\n\n\n\nTakeaways and Observations\n\n\n\n\n\nSep 3, 2025\n\n\nAngelica\n\n\n\n\n\nNo matching items"
  }
]