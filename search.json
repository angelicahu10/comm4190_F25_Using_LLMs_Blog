[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Journal of Exploring and Experimenting With LLMs",
    "section": "",
    "text": "My First Blog Post!\n\n\n\nMy Profile\n\n\n\nGet to Know Me\n\n\n\n\n\nSep 3, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nThe Wolfram Article\n\n\n\nMy Profile\n\n\n\nTakeaways and Observations\n\n\n\n\n\nSep 3, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/002_wolfram_article/wolfram.html",
    "href": "posts/002_wolfram_article/wolfram.html",
    "title": "The Wolfram Article",
    "section": "",
    "text": "The way that LLMs basically create output is with ‚Äúreasonable continuation,‚Äù looking at the response with the highest probability. I think it‚Äôs super interesting to learn that ChatGpt or other models are basically just making their best guesses at what makes sense, using lots of randomness to come up with non-flat responses. There‚Äôs an infinite combination of possible sequences with no correct answer. It was super cool to see how the next word that is outputted is based on the previous word, which then becomes sequences. I found it much easier to understand this complex process when breaking it down from letters, to words, to sentences.\n\nI tried to follow the coding in my Jupyter notebook but learned that the code in the article followed Mathematica/Wolfram syntax instead of Python syntax. I‚Äôm interested to learn what differentiates the two, and how to convert them to work with certin models.\nI was also surprised to learn that there are 40,000 reasonably common words in English. While I know English is a vast language, I had never given it much thought how many words I typically use on a daily basis or the words used in conversation!"
  },
  {
    "objectID": "posts/002_wolfram_article/wolfram.html#section",
    "href": "posts/002_wolfram_article/wolfram.html#section",
    "title": "The Wolfram Article",
    "section": "",
    "text": "The way that LLMs basically create output is with ‚Äúreasonable continuation,‚Äù looking at the response with the highest probability. I think it‚Äôs super interesting to learn that ChatGpt or other models are basically just making their best guesses at what makes sense, using lots of randomness to come up with non-flat responses. There‚Äôs an infinite combination of possible sequences with no correct answer. It was super cool to see how the next word that is outputted is based on the previous word, which then becomes sequences. I found it much easier to understand this complex process when breaking it down from letters, to words, to sentences.\n\nI tried to follow the coding in my Jupyter notebook but learned that the code in the article followed Mathematica/Wolfram syntax instead of Python syntax. I‚Äôm interested to learn what differentiates the two, and how to convert them to work with certin models.\nI was also surprised to learn that there are 40,000 reasonably common words in English. While I know English is a vast language, I had never given it much thought how many words I typically use on a daily basis or the words used in conversation!"
  },
  {
    "objectID": "posts/001_first_post/personal_info.html",
    "href": "posts/001_first_post/personal_info.html",
    "title": "My First Blog Post!",
    "section": "",
    "text": "Hello! My name is Angelica and this first blog post is going to be getting to know a little bit about me while I explore how to use this platform! My experience with data science/coding comes from PHYS1100: Foundations of Data Science, which I took last semester as well as some other coding experience I did in high school."
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#hello",
    "href": "posts/001_first_post/personal_info.html#hello",
    "title": "My First Blog Post!",
    "section": "",
    "text": "Hello! My name is Angelica and this first blog post is going to be getting to know a little bit about me while I explore how to use this platform! My experience with data science/coding comes from PHYS1100: Foundations of Data Science, which I took last semester as well as some other coding experience I did in high school."
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#my-family",
    "href": "posts/001_first_post/personal_info.html#my-family",
    "title": "My First Blog Post!",
    "section": "My Family",
    "text": "My Family\nMy parents are from China, but me and my two older sisters were born here which makes us second generation. My older sisters both live in New York City now after graduating from college. This photo is from June from my middle sister‚Äôs college graduation in Evanston, Illinois. I loveee Chicago!\nWe also have a dog named Minnie! She‚Äôs a goldendoodle and turning 11 this year. I miss her a lot!"
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#academics",
    "href": "posts/001_first_post/personal_info.html#academics",
    "title": "My First Blog Post!",
    "section": "Academics",
    "text": "Academics\nHere at Penn, I‚Äôm studying Health and Societies with a concentration in Healthcare Markets and Finance and a minor in Data Science and Analytics. I hope to explore the healthcare system and work towards fixing health disparities and improve access and quality, perhaps through healthcare data analytics!"
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#interests",
    "href": "posts/001_first_post/personal_info.html#interests",
    "title": "My First Blog Post!",
    "section": "Interests",
    "text": "Interests\nI love competitive swimming as I‚Äôve swam my whole life. I also am a big foodie and love trying new resturants! My favorite shows are Friends, How I Met Your Mother, funny sit coms like that. I‚Äôm super excited to learm more about LLMs and AI in this class!\n\n(me when i understand how to use github and face no technical difficulties)"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "My Experience In COMM4190",
    "section": "",
    "text": "Angelica Hu"
  }
]