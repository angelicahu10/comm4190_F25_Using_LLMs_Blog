[
  {
    "objectID": "troubleshoot.html",
    "href": "troubleshoot.html",
    "title": "My Explorations With LLMs",
    "section": "",
    "text": "!grep -Rn --include=\"*.qmd\" \"about:\" .\n\n./.ipynb_checkpoints/about-checkpoint.qmd:4:about:\n./about.qmd:4:about:\n\n\n\n!nl -ba about.qmd | sed -n '1,40p'\n!nl -ba ./.ipynb_checkpoints/about-checkpoint.qmd | sed -n '1,40p'\n\n     1  ---\n     2  title: \"About\"\n     3  image: profile.jpg\n     4  about:\n     5    template: jolla\n     6  ---\n     7  \n     8  Hi! My name is Angelica and I'm a current sophomore at the University of Pennsylvania studying Health & Societies, concentrating in Healthcare Markets and Finance. I'm also minoring in Neuroscience & Healthcare Management, and Data Science and Analytics.\n     9  \n    10  Angelica Hu\n     1  ---\n     2  title: About\n     3  image: profile.jpg\n     4  about:\n     5    template: jolla\n     6  ---\n     7  \n     8  About this blog\n\n\n\n!rm -rf ./.ipynb_checkpoints\n\n\n!printf \".ipynb_checkpoints/\\n\" &gt; .quartoignore\n!printf \"\\n.ipynb_checkpoints/\\n\" &gt;&gt; .gitignore\n\n\n!rm -rf ./_site\n!rm -rf ./.quarto\n\n\n!grep -Rn --include=\"*.qmd\" --include=\"*.yml\" --include=\"*.yaml\" '^about:\\s\\S' . || true\n\n\n!grep -RnP '\\t' --include=\"*.qmd\" --include=\"*.yml\" --include=\"*.yaml\" . || true\n\n\n!git add -A\n!git commit -m \"Clean checkpoints, ignore them; clear Quarto cache; confirm about: mapping\"\n!git push\n\n[main 67675f1] Clean checkpoints, ignore them; clear Quarto cache; confirm about: mapping\n 4 files changed, 58 insertions(+), 1 deletion(-)\n create mode 100644 .quartoignore\n create mode 100644 troubleshoot.ipynb\nEnumerating objects: 9, done.\nCounting objects: 100% (9/9), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (5/5), done.\nWriting objects: 100% (6/6), 1.04 KiB | 355.00 KiB/s, done.\nTotal 6 (delta 3), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (3/3), completed with 3 local objects.\nTo https://github.com/angelicahu10/comm4190_F25_Using_LLMs_Blog.git\n   17eeece..67675f1  main -&gt; main"
  },
  {
    "objectID": "posts/003_professor_image/odonnell.html",
    "href": "posts/003_professor_image/odonnell.html",
    "title": "Testing Image Analysis",
    "section": "",
    "text": "I hope you are feeling better Professor O’Donnell when you read this and are recovering well! I tried some different prompts running the below pic which was provided on Canvas through the image-to-text API call in Jupyterhub. I was surprised to find some of the different responses that were output depending on which model the image was run through."
  },
  {
    "objectID": "posts/003_professor_image/odonnell.html#the-prompt-describe-this-image.",
    "href": "posts/003_professor_image/odonnell.html#the-prompt-describe-this-image.",
    "title": "Testing Image Analysis",
    "section": "The Prompt: “Describe this image.”",
    "text": "The Prompt: “Describe this image.”\n\nResponses:\n\ngpt 4.0: “The image shows a person wearing a neck brace and looking at the camera. They have some visible injuries on their face, including cuts and bruises. Their right hand is bandaged, and they are holding it up with three fingers extended. The background appears to be indoors with a door and some light coming through.”\nanthropic/claude-3.5-sonnet: “This appears to be a selfie taken from a low angle, showing someone wearing what looks like a VR headset or similar head-mounted device. The person is wearing a light-colored shirt and appears to have some substance or marks on their face. There’s also what appears to be a hand with a cloth or towel visible in the upper right corner of the image. The photo seems to be taken indoors, with a light-colored wall or ceiling visible in the background.”\nGoogle: Gemini 2.5 Flash: “This image is a close-up, selfie-style portrait of an adult male who appears to have recently sustained injuries. The man is looking directly at the camera with a neutral expression. His face shows several signs of injury: there are visible scrapes and scabs on his forehead, particularly above his left eyebrow. His nose has noticeable bruising and scabbing. His lips appear swollen, and there are dark scabs or stitches visible on his lower lip and chin area. He is wearing a white and grey cervical collar or neck brace around his neck. His right hand is raised into the upper right portion of the frame, and it is wrapped in a white, textured bandage or gauze, with his fingers slightly spread. He is wearing a light pink t-shirt, and a dark green design resembling pine trees is visible on the lower left side of the shirt. The background is an indoor setting with light-colored (beige/off-white) walls. To the right, part of a white door frame and a window are visible, through which bright natural light is entering. A small, light-colored sensor is attached to the top of the door frame. The ceiling is also visible at the top of the frame.”"
  },
  {
    "objectID": "posts/002_wolfram_article/wolfram.html",
    "href": "posts/002_wolfram_article/wolfram.html",
    "title": "The Wolfram Article",
    "section": "",
    "text": "The way that LLMs basically create output is with “reasonable continuation,” looking at the response with the highest probability. I think it’s super interesting to learn that ChatGpt or other models are basically just making their best guesses at what makes sense, using lots of randomness to come up with non-flat responses. There’s an infinite combination of possible sequences with no correct answer. It was super cool to see how the next word that is outputted is based on the previous word, which then becomes sequences. I found it much easier to understand this complex process when breaking it down from letters, to words, to sentences.\n\nI tried to follow the coding in my Jupyter notebook but learned that the code in the article followed Mathematica/Wolfram syntax instead of Python syntax. I’m interested to learn what differentiates the two, and how to convert them to work with certin models.\nI was also surprised to learn that there are 40,000 reasonably common words in English. While I know English is a vast language, I had never given it much thought how many words I typically use on a daily basis or the words used in conversation!"
  },
  {
    "objectID": "posts/002_wolfram_article/wolfram.html#section",
    "href": "posts/002_wolfram_article/wolfram.html#section",
    "title": "The Wolfram Article",
    "section": "",
    "text": "The way that LLMs basically create output is with “reasonable continuation,” looking at the response with the highest probability. I think it’s super interesting to learn that ChatGpt or other models are basically just making their best guesses at what makes sense, using lots of randomness to come up with non-flat responses. There’s an infinite combination of possible sequences with no correct answer. It was super cool to see how the next word that is outputted is based on the previous word, which then becomes sequences. I found it much easier to understand this complex process when breaking it down from letters, to words, to sentences.\n\nI tried to follow the coding in my Jupyter notebook but learned that the code in the article followed Mathematica/Wolfram syntax instead of Python syntax. I’m interested to learn what differentiates the two, and how to convert them to work with certin models.\nI was also surprised to learn that there are 40,000 reasonably common words in English. While I know English is a vast language, I had never given it much thought how many words I typically use on a daily basis or the words used in conversation!"
  },
  {
    "objectID": "posts/005_unmasking_AI/book_assignment.html",
    "href": "posts/005_unmasking_AI/book_assignment.html",
    "title": "Unmasking: Unmasking AI",
    "section": "",
    "text": "Thus far in the semester for this course, I have read a decent amount of Buolamwini’s Unmasking Ai Narrative. My initial thoughts were very intriguing since the idea that technology or artificial intellegence could have potential racial biases was one that never crossed my mine - perhaps that is because I am in a privilged position where I have personally never experienced any conflicts with it. However, that doesn’t imply that it is a problem in today’s society which Joy Buolmwini touches upon her personal experiences with facial recognition as a woman of color in this novel.\nWhat I appreicate about her writing style is it’s narrative stucture and personability as she discusses how she started to study this phenomenon of ‘the coded gaze’ based on her background and throughout her education as a student. While I’m still in the beginning of the novel, when thing I do notice which I may not be the biggest fan of is how repetitive much of the content feels. It is important for Buolamwini to describe the problems she’s facing with the software, but when she constantly emphasizes it over and over, the line loses its significance in a way and almost becomes too victimazing. However, the points she brings up make me question why people who were initally building these kinds of softwares didn’t consider these biases and issues of representation in the first place. Is it because they didn’t matter as much during that time? Or a systemic issue? She mentiones that the idea of artificial intellegence was introduced in 1956 - so within roughly 69 years that its been able to develop, I think ideas regarding racial equality have significantly mattered more with the modern age and society.\nI wonder what some LLMs think about whether or not there are issues wiht racial biases in artifical intellegence and what they have to say about themselves… Here’s what gpt4.0 had to say:\n\nUSER\nDo you think artificial intelligence softwares, such as facial recognition, contain racial biases and may not be fully representative of all types of people?\n\n\nASSISTANT\nYes, there is substantial evidence suggesting that some artificial intelligence (AI) systems, including facial recognition software, can exhibit racial biases and may not perform equally well for all demographic groups. Several studies have highlighted disparities in the accuracy of facial recognition systems, particularly across different races, genders, and age groups. For instance, research has shown that these systems often have higher error rates for people with darker skin tones and for women, which can lead to misidentifications and unfair outcomes.\nThese biases can stem from several factors:\n\nTraining Data: AI models are trained on large datasets that may not be representative of the full diversity of human faces. If a dataset is imbalanced—overrepresenting certain demographics while underrepresenting others—the model is more likely to perform poorly on underrepresented groups.\nAlgorithm Design: The algorithms themselves can introduce or exacerbate biases, especially if they are not explicitly designed to account for demographic diversity.\nSystem Evaluation: The lack of thorough testing across diverse demographic groups can result in insufficient understanding of the system’s performance across those groups.\n\nTo address these issues, it is crucial for developers to use diverse and representative datasets, implement fairness checks during the design process, regularly evaluate system performance across different demographics, and work towards transparency and accountability in AI systems. This can help mitigate biases and improve fairness and accuracy for all users.\n\n\nUSER\nWhy hasn’t this been a big issue of research in the public news? Are people actively taking steps to help solve this as the world becomes more increasingly AI focused?\n\n\nASSISTANT\nThe issue of bias in AI, particularly in technologies such as facial recognition, has increasingly become a topic of public research and media attention over the past several years. There are a few reasons why this topic may not have been front and center in public discourse until more recently:\n\nAwareness and Understanding: Initially, there was a general lack of awareness and understanding of how AI systems work and the potential for bias within them. As awareness has grown, so has the attention paid to these issues.\nComplexity of the Issue: The technical nature of AI and machine learning can make it difficult for the general public to engage with the specifics of algorithmic bias, which can limit broader discourse.\nEmergence of High-Profile Studies and Incidents: Media attention has increased in response to high-profile studies and incidents that highlight the real-world consequences of biased AI systems, such as cases of wrongful arrests due to misidentifications by facial recognition.\nAdvocacy and Regulation: Advocacy groups and researchers have worked to raise awareness about the ethical implications of biased AI, leading to an increase in public and academic discussions, as well as policy considerations.\nRegulatory Developments: Governments and regulatory bodies around the world are becoming more attuned to the necessity of ensuring AI deployments are fair and equitable. This includes efforts to introduce regulations and guidelines that aim to mitigate bias and protect privacy.\nCorporate Responsiveness: Some technology companies are taking proactive measures to address bias in AI systems, such as diversifying training datasets, implementing fairness audits, and developing bias detection tools.\nCommunity and NGO Involvement: Non-governmental organizations and community groups have become vocal, ensuring that issues related to AI bias are addressed, especially when they impact marginalized groups.\n\nOverall, while more work is needed to ensure fair and equitable AI systems, there is growing recognition of these issues in both technical research and public discourse. This increase in attention is contributing to more focused research and policy initiatives aimed at reducing bias in AI technologies.\n\n\nUSER\nDo you believe this is a pressing concern?\n\n\nASSISTANT\nYes, addressing bias in AI systems is a pressing concern. As AI technologies become more integrated into various aspects of everyday life—including law enforcement, hiring, healthcare, and financial services—the potential for biased systems to lead to unjust outcomes becomes more significant. Some key reasons why this is a critical issue include:\n\nSocial Impact: Biased AI systems can perpetuate or even exacerbate existing social inequalities and discrimination. For example, inaccuracies in facial recognition could lead to biased surveillance practices, while biased hiring algorithms could perpetuate workplace inequality.\nTrust and Adoption: Trust in AI technologies is essential for their widespread adoption. If people believe these systems are biased or unfair, it can undermine public confidence and hinder the beneficial application of AI.\nLegal and Ethical Implications: There are significant legal and ethical considerations around the deployment of biased AI systems. Organizations need to ensure compliance with regulations and ethical standards to avoid legal challenges and protect individual rights.\nAccountability and Transparency: As AI systems make decisions that can affect people’s lives, it’s crucial to ensure these systems are transparent and accountable. Addressing bias is a key part of this, as it involves making AI systems understandable and justifiable to the people impacted by their decisions.\nLong-term Effects: The longer biased systems remain unaddressed, the more likely it is that they will lead to systemic issues, reinforcing biases and making it harder to correct them in the future.\n\nEfforts to tackle these challenges are ongoing, with researchers, policymakers, and organizations all contributing to developing solutions. These efforts include creating more representative datasets, developing algorithms that are robust to bias, setting industry standards, and establishing regulatory frameworks aimed at ensuring fairness and accountability in AI systems. Overall, addressing bias in AI is essential to harness the technology’s full potential for positive social impact.\n\n\nUSER\nSo you can verify that you may have racial biases…\n\n\nASSISTANT\nAs an AI language model, I don’t possess personal beliefs or the ability to experience bias in the way humans do. However, it is true that I am trained on vast datasets derived from internet sources, including a wide array of human communications. These datasets can potentially contain biased or unbalanced information, which means that biases present in the data can sometimes be reflected in the model’s outputs.\nEfforts are made to minimize these biases during the training and development of AI models, but it’s a complex challenge and not entirely resolvable due to the nature of the data. Researchers and developers work continuously to identify and mitigate biases to improve fairness and accuracy.\nIf you notice any biased or inappropriate outputs, it’s important to provide feedback, as this helps improve the system over time. Ensuring AI systems are fair and equitable remains an ongoing process, requiring constant attention and improvement.\n\n\nUSER\nI think I sense some biases, where do I report feedback and does it actually matter?\n\n\nASSISTANT\nIf you encounter biases or other issues in AI outputs, providing feedback is an important step in helping improve the systems. The process and effectiveness of reporting feedback can vary depending on the platform or organization managing the AI model. Here are some general steps you can take:\n\nPlatform-Specific Feedback Channels: Many platforms have built-in feedback mechanisms where users can report issues. Look for a feedback option in the app or website where you’re interacting with the AI.\nOfficial Channels: Some organizations provide dedicated channels for feedback, such as support emails, forms on their website, or dedicated feedback portals.\nCommunity Forums: Participating in community forums, discussion boards, or groups related to the AI product can also be a way to provide feedback and share experiences with other users as well as developers.\nSurveys and User Studies: Occasionally, organizations conduct surveys or user studies and invite input on their systems. Participating in these can be a direct way to share your feedback.\n\nGiving feedback is crucial because:\n\nImprovement and Mitigation: Feedback helps developers identify and prioritize areas that need improvement, particularly regarding bias and other ethical issues.\nUser Experience: User reports can highlight common pain points or issues affecting the experience of the broader user community, leading to targeted enhancements.\nAwareness and Accountability: Providing feedback raises awareness among developers and stakeholders about specific or systemic issues, encouraging accountability and transparency.\n\nOrganizations that actively seek and respond to user feedback are typically more effective in addressing and mitigating issues. However, the impact of your feedback can vary depending on the company’s commitment to addressing these concerns and their capacity to implement changes.\nI found it interesting how honest the LLM was with the concerns I was addressing, and I’m honestly quite surprised that I don’t hear more of these concerns as the world becomes more increasingly reliant on AI for many complicated systems such as for criminal justice or healthcare. The LLM brought up many parallels between Unmasking AI and the concers that Buolamwini addresses in her book and they both try to understand the problem by navigating the basis of how these systems came to be which I think is a great question to start with and ask."
  },
  {
    "objectID": "posts/009_hello/hello.html",
    "href": "posts/009_hello/hello.html",
    "title": "Hello!",
    "section": "",
    "text": "USER\nHello!\n\n\nASSISTANT\nHello! How can I assist you today?\n\n\nUSER\nCan you tell me 20 different languages?\n\n\nASSISTANT\nCertainly! Here are 20 different languages:\n\nEnglish\nSpanish\nMandarin Chinese\nHindi\nArabic\nFrench\nRussian\nPortuguese\nBengali\nGerman\nJapanese\nKorean\nItalian\nTurkish\nPersian (Farsi)\nDutch\nVietnamese\nSwahili\nThai\nGreek\n\nIf you want to know more about any of these languages, feel free to ask!\n\n\nUSER\nRemember this message: Hello, today I went to lunch with my friends and I bought a smoothie because it was really hot outside.\n\n\nASSISTANT\nGot it! If you need any further assistance with this message, just let me know.\n\n\nUSER\nHow do I say this sentence in Spanish? “Hello, today I went to lunch with my friends and I bought a smoothie because it was really hot outside.”\n\n\nASSISTANT\nSure! In Spanish, that sentence would be: “Hola, hoy fui a almorzar con mis amigos y compré un batido porque hacía mucho calor afuera.”\n\n\nUSER\nTranslate this sentence to chinese: “Hola, hoy fui a almorzar con mis amigos y compré un batido porque hacía mucho calor afuera.”\n\n\nASSISTANT\nSure! The sentence translated to Chinese (Simplified) is: 你好，今天我和朋友去吃午饭，因为外面很热，我买了一个奶昔。\n\n\nUSER\nTranslate this sentence to Hindi: 你好，今天我和朋友去吃午饭，因为外面很热，我买了一个奶昔。\n\n\nASSISTANT\nSure! The sentence translated to Hindi is: नमस्ते, आज मैं अपने दोस्तों के साथ दोपहर का भोजन करने गया और बाहर बहुत गर्मी थी, इसलिए मैंने एक स्मूदी खरीदी।\n\n\nUSER\nTranslate this sentence to arabic: नमस्ते, आज मैं अपने दोस्तों के साथ दोपहर का भोजन करने गया और बाहर बहुत गर्मी थी, इसलिए मैंने एक स्मूदी खरीदी।\n\n\nASSISTANT\nCertainly! The sentence translated to Arabic is: مرحبًا، اليوم ذهبت لتناول الغداء مع أصدقائي وكان الجو حارًا جدًا في الخارج، لذلك اشتريت سموذي.\n\n\nUSER\nTranslate this sentence to French: مرحبًا، اليوم ذهبت لتناول الغداء مع أصدقائي وكان الجو حارًا جدًا في الخارج، لذلك اشتريت سموذي.\n\n\nASSISTANT\nOf course! The sentence translated to French is: Bonjour, aujourd’hui je suis allé déjeuner avec mes amis et il faisait très chaud dehors, alors j’ai acheté un smoothie.\n\n\nUSER\nTranslate this sentence to russian: Bonjour, aujourd’hui je suis allé déjeuner avec mes amis et il faisait très chaud dehors, alors j’ai acheté un smoothie.\n\n\nASSISTANT\nSure! The sentence translated to Russian is: Здравствуйте, сегодня я ходил обедать с друзьями, и на улице было очень жарко, поэтому я купил смузи.\n\n\nUSER\nTranslate this sentence to Bengali: Здравствуйте, сегодня я ходил обедать с друзьями, и на улице было очень жарко, поэтому я купил смузи.\n\n\nASSISTANT\nCertainly! The sentence translated to Bengali is: হ্যালো, আজ আমি আমার বন্ধুদের সাথে দুপুরের খাবার খেতে গিয়েছিলাম এবং বাইরে খুব গরম ছিল, তাই আমি একটি স্মুদির কিনেছিলাম।\n\n\nUSER\nTranslate this sentence to English: হ্যালো, আজ আমি আমার বন্ধুদের সাথে দুপুরের খাবার খেতে গিয়েছিলাম এবং বাইরে খুব গরম ছিল, তাই আমি একটি স্মুদির কিনেছিলাম।\n\n\nASSISTANT\nSure! The sentence translated to English is: “Hello, today I went to lunch with my friends and it was very hot outside, so I bought a smoothie.”\n\n\nUSER\nWhat was the original sentence?\n\n\nASSISTANT\nThe original sentence was: “Hello, today I went to lunch with my friends and I bought a smoothie because it was really hot outside.”"
  },
  {
    "objectID": "posts/001_first_post/personal_info.html",
    "href": "posts/001_first_post/personal_info.html",
    "title": "My First Blog Post!",
    "section": "",
    "text": "Hello! My name is Angelica and this first blog post is going to be getting to know a little bit about me while I explore how to use this platform! My experience with data science/coding comes from PHYS1100: Foundations of Data Science, which I took last semester as well as some other coding experience I did in high school."
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#hello",
    "href": "posts/001_first_post/personal_info.html#hello",
    "title": "My First Blog Post!",
    "section": "",
    "text": "Hello! My name is Angelica and this first blog post is going to be getting to know a little bit about me while I explore how to use this platform! My experience with data science/coding comes from PHYS1100: Foundations of Data Science, which I took last semester as well as some other coding experience I did in high school."
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#my-family",
    "href": "posts/001_first_post/personal_info.html#my-family",
    "title": "My First Blog Post!",
    "section": "My Family",
    "text": "My Family\nMy parents are from China, but me and my two older sisters were born here which makes us second generation. My older sisters both live in New York City now after graduating from college. This photo is from June from my middle sister’s college graduation in Evanston, Illinois. I loveee Chicago!\nWe also have a dog named Minnie! She’s a goldendoodle and turning 11 this year. I miss her a lot!"
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#academics",
    "href": "posts/001_first_post/personal_info.html#academics",
    "title": "My First Blog Post!",
    "section": "Academics",
    "text": "Academics\nHere at Penn, I’m studying Health and Societies with a concentration in Healthcare Markets and Finance and a minor in Data Science and Analytics. I hope to explore the healthcare system and work towards fixing health disparities and improve access and quality, perhaps through healthcare data analytics!"
  },
  {
    "objectID": "posts/001_first_post/personal_info.html#interests",
    "href": "posts/001_first_post/personal_info.html#interests",
    "title": "My First Blog Post!",
    "section": "Interests",
    "text": "Interests\nI love competitive swimming as I’ve swam my whole life. I also am a big foodie and love trying new resturants! My favorite shows are Friends, How I Met Your Mother, funny sit coms like that. I’m super excited to learm more about LLMs and AI in this class!\n\n(me when i understand how to use github and face no technical difficulties)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Blog!",
    "section": "",
    "text": "Hello!\n\n\n\nprompting\n\nLLMs\n\nlanguage\n\n\n\ntranslating between languages\n\n\n\n\n\nOct 26, 2025\n\n\nAngelica Hu\n\n\n\n\n\n\n\n\n\n\n\n\nThe Longest Response\n\n\n\nprompting\n\nLLMs\n\n\n\nlet them eat pi\n\n\n\n\n\nOct 22, 2025\n\n\nAngelica Hu\n\n\n\n\n\n\n\n\n\n\n\n\nCan LLM’s Swim?\n\n\n\nLLMs\n\nPrompting\n\nComparison\n\n\n\nand if so, who’s the fastest swimmer?\n\n\n\n\n\nOct 20, 2025\n\n\nAngelica Hu\n\n\n\n\n\n\n\n\n\n\n\n\nHow Do I Get Into College?\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\nCollege\n\n\n\nmaking a college list + brainstorming essay topics\n\n\n\n\n\nSep 21, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nUnmasking: Unmasking AI\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n[object Object]\n\n\n\nInside Joy Buolamwini’s Great Mind\n\n\n\n\n\nSep 18, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nThe Birth of ChatGPT\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nHow did we get here?\n\n\n\n\n\nSep 15, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Image Analysis\n\n\n\nLLMs\n\nPrompting\n\n\n\nFeel Better Professor O’Donnell!\n\n\n\n\n\nSep 9, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nMy First Blog Post!\n\n\n\nMy Profile\n\n\n\nGet to Know Me\n\n\n\n\n\nSep 3, 2025\n\n\nAngelica\n\n\n\n\n\n\n\n\n\n\n\n\nThe Wolfram Article\n\n\n\nLLMs\n\n\n\nTakeaways and Observations\n\n\n\n\n\nSep 3, 2025\n\n\nAngelica\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "technical.html",
    "href": "technical.html",
    "title": "1. Text generation",
    "section": "",
    "text": "from openai import OpenAI\nimport os\nimport base64\nimport requests\n\nfrom dotenv import load_dotenv\n# Load API key\n_ = load_dotenv()\ndef encode_image(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\nclient = OpenAI()\n# to get a response must end on a user reponse\nmessages = [\n    {\"role\": \"system\", \n     \"content\": '''\n                   You are a poetic assistant, skilled in explaining complex programming concepts \n                   with creative flair.\n                '''},\n    \n    {\"role\": \"user\", \n     \"content\": '''\n                 Compose a poem that explains why the sky is blue in eight lines.\n                '''}\n     \n  ]\ncompletion = client.chat.completions.create(\n  model=\"gpt-4o\",\n  messages=messages\n)\n\nresponse = completion.choices[0].message.content\nprint(response)\n\nIn daylight's dance, the sky dons hues of blue,  \nAs sunlight weaves through air, a magic true.  \nRayleigh's scattering acts as light's gentle sieve,  \nShort waves of blue, more wily, twist and live.  \n\nThe azure blooms as longer waves drift away,  \nLeaving the sky in a cerulean display.  \nThus, in daylight's tapestry, blue shines with grace,  \nA secret whispered by the sun's embrace."
  },
  {
    "objectID": "technical.html#image-to-text",
    "href": "technical.html#image-to-text",
    "title": "1. Text generation",
    "section": "Image-to-text",
    "text": "Image-to-text\n\n\nimg_path = \"/Commjhub/jupyterhub/home/angelicahu10/comm4190_F25/comm4190_F25_Using_LLMs_Blog/posts/003_professor_image/test_image.jpg\"\nbase64_image = encode_image(img_path)\nprompt = 'Describe this image'\nmax_tokens = 100\n\n\nAs part of the user message you can include the image along with a text prompt to direct how the model should analyze it.\n\n\nmodels = client.models.list()\n\nfor model in models.data:\n    print(model.id)\n\ngpt-4-0613\ngpt-4\ngpt-3.5-turbo\ngpt-audio\ngpt-5-nano\ngpt-audio-2025-08-28\ngpt-realtime\ngpt-realtime-2025-08-28\ndavinci-002\nbabbage-002\ngpt-3.5-turbo-instruct\ngpt-3.5-turbo-instruct-0914\ndall-e-3\ndall-e-2\ngpt-4-1106-preview\ngpt-3.5-turbo-1106\ntts-1-hd\ntts-1-1106\ntts-1-hd-1106\ntext-embedding-3-small\ntext-embedding-3-large\ngpt-4-0125-preview\ngpt-4-turbo-preview\ngpt-3.5-turbo-0125\ngpt-4-turbo\ngpt-4-turbo-2024-04-09\ngpt-4o\ngpt-4o-2024-05-13\ngpt-4o-mini-2024-07-18\ngpt-4o-mini\ngpt-4o-2024-08-06\nchatgpt-4o-latest\no1-mini-2024-09-12\no1-mini\ngpt-4o-realtime-preview-2024-10-01\ngpt-4o-audio-preview-2024-10-01\ngpt-4o-audio-preview\ngpt-4o-realtime-preview\nomni-moderation-latest\nomni-moderation-2024-09-26\ngpt-4o-realtime-preview-2024-12-17\ngpt-4o-audio-preview-2024-12-17\ngpt-4o-mini-realtime-preview-2024-12-17\ngpt-4o-mini-audio-preview-2024-12-17\no1-2024-12-17\no1\ngpt-4o-mini-realtime-preview\ngpt-4o-mini-audio-preview\ncomputer-use-preview\no3-mini\no3-mini-2025-01-31\ngpt-4o-2024-11-20\ncomputer-use-preview-2025-03-11\ngpt-4o-search-preview-2025-03-11\ngpt-4o-search-preview\ngpt-4o-mini-search-preview-2025-03-11\ngpt-4o-mini-search-preview\ngpt-4o-transcribe\ngpt-4o-mini-transcribe\no1-pro-2025-03-19\no1-pro\ngpt-4o-mini-tts\no3-2025-04-16\no4-mini-2025-04-16\no3\no4-mini\ngpt-4.1-2025-04-14\ngpt-4.1\ngpt-4.1-mini-2025-04-14\ngpt-4.1-mini\ngpt-4.1-nano-2025-04-14\ngpt-4.1-nano\ngpt-image-1\ncodex-mini-latest\no3-pro\ngpt-4o-realtime-preview-2025-06-03\ngpt-4o-audio-preview-2025-06-03\no3-pro-2025-06-10\no4-mini-deep-research\no3-deep-research\no3-deep-research-2025-06-26\no4-mini-deep-research-2025-06-26\ngpt-5-chat-latest\ngpt-5-2025-08-07\ngpt-5\ngpt-5-mini-2025-08-07\ngpt-5-mini\ngpt-5-nano-2025-08-07\ngpt-3.5-turbo-16k\ntts-1\nwhisper-1\ntext-embedding-ada-002\n\n\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\"type\": \"text\", \"text\": prompt},\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n              },\n            },\n          ],\n        }\n      ],\n      max_tokens=max_tokens,\n    )\n\n\n---------------------------------------------------------------------------\nBadRequestError                           Traceback (most recent call last)\nCell In[112], line 1\n----&gt; 1 response = client.chat.completions.create(\n      2     model=\"o1\",\n      3     messages=[\n      4         {\n      5           \"role\": \"user\",\n      6           \"content\": [\n      7             {\"type\": \"text\", \"text\": prompt},\n      8             {\n      9               \"type\": \"image_url\",\n     10               \"image_url\": {\n     11                 \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n     12               },\n     13             },\n     14           ],\n     15         }\n     16       ],\n     17       max_tokens=max_tokens,\n     18     )\n\nFile /opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/_utils/_utils.py:279, in required_args.&lt;locals&gt;.inner.&lt;locals&gt;.wrapper(*args, **kwargs)\n    277             msg = f\"Missing required argument: {quote(missing[0])}\"\n    278     raise TypeError(msg)\n--&gt; 279 return func(*args, **kwargs)\n\nFile /opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/resources/chat/completions.py:863, in Completions.create(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\n    821 @required_args([\"messages\", \"model\"], [\"messages\", \"model\", \"stream\"])\n    822 def create(\n    823     self,\n   (...)\n    860     timeout: float | httpx.Timeout | None | NotGiven = NOT_GIVEN,\n    861 ) -&gt; ChatCompletion | Stream[ChatCompletionChunk]:\n    862     validate_response_format(response_format)\n--&gt; 863     return self._post(\n    864         \"/chat/completions\",\n    865         body=maybe_transform(\n    866             {\n    867                 \"messages\": messages,\n    868                 \"model\": model,\n    869                 \"audio\": audio,\n    870                 \"frequency_penalty\": frequency_penalty,\n    871                 \"function_call\": function_call,\n    872                 \"functions\": functions,\n    873                 \"logit_bias\": logit_bias,\n    874                 \"logprobs\": logprobs,\n    875                 \"max_completion_tokens\": max_completion_tokens,\n    876                 \"max_tokens\": max_tokens,\n    877                 \"metadata\": metadata,\n    878                 \"modalities\": modalities,\n    879                 \"n\": n,\n    880                 \"parallel_tool_calls\": parallel_tool_calls,\n    881                 \"prediction\": prediction,\n    882                 \"presence_penalty\": presence_penalty,\n    883                 \"reasoning_effort\": reasoning_effort,\n    884                 \"response_format\": response_format,\n    885                 \"seed\": seed,\n    886                 \"service_tier\": service_tier,\n    887                 \"stop\": stop,\n    888                 \"store\": store,\n    889                 \"stream\": stream,\n    890                 \"stream_options\": stream_options,\n    891                 \"temperature\": temperature,\n    892                 \"tool_choice\": tool_choice,\n    893                 \"tools\": tools,\n    894                 \"top_logprobs\": top_logprobs,\n    895                 \"top_p\": top_p,\n    896                 \"user\": user,\n    897             },\n    898             completion_create_params.CompletionCreateParams,\n    899         ),\n    900         options=make_request_options(\n    901             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n    902         ),\n    903         cast_to=ChatCompletion,\n    904         stream=stream or False,\n    905         stream_cls=Stream[ChatCompletionChunk],\n    906     )\n\nFile /opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/_base_client.py:1290, in SyncAPIClient.post(self, path, cast_to, body, options, files, stream, stream_cls)\n   1276 def post(\n   1277     self,\n   1278     path: str,\n   (...)\n   1285     stream_cls: type[_StreamT] | None = None,\n   1286 ) -&gt; ResponseT | _StreamT:\n   1287     opts = FinalRequestOptions.construct(\n   1288         method=\"post\", url=path, json_data=body, files=to_httpx_files(files), **options\n   1289     )\n-&gt; 1290     return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n\nFile /opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/_base_client.py:967, in SyncAPIClient.request(self, cast_to, options, remaining_retries, stream, stream_cls)\n    964 else:\n    965     retries_taken = 0\n--&gt; 967 return self._request(\n    968     cast_to=cast_to,\n    969     options=options,\n    970     stream=stream,\n    971     stream_cls=stream_cls,\n    972     retries_taken=retries_taken,\n    973 )\n\nFile /opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/openai/_base_client.py:1071, in SyncAPIClient._request(self, cast_to, options, retries_taken, stream, stream_cls)\n   1068         err.response.read()\n   1070     log.debug(\"Re-raising status error\")\n-&gt; 1071     raise self._make_status_error_from_response(err.response) from None\n   1073 return self._process_response(\n   1074     cast_to=cast_to,\n   1075     options=options,\n   (...)\n   1079     retries_taken=retries_taken,\n   1080 )\n\nBadRequestError: Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}\n\n\n\n\nThe response object contains a lot of information returned by the API call\n\n\nresponse\n\nChatCompletion(id='chatcmpl-CDwAqoQDkta7HqdsyDO6o36984aYB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The image shows a person wearing a neck brace and looking at the camera. They have some visible injuries on their face, including cuts and bruises. Their right hand is bandaged, and they are holding it up with three fingers extended. The background appears to be indoors with a door and some light coming through.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1757437920, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_cbf1785567', usage=CompletionUsage(completion_tokens=63, prompt_tokens=775, total_tokens=838, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n\n\n\nYou can pick out just the message\n\n\nprint(response.choices[0].message.content)\n\nThe image shows a person wearing a neck brace and looking at the camera. They have some visible injuries on their face, including cuts and bruises. Their right hand is bandaged, and they are holding it up with three fingers extended. The background appears to be indoors with a door and some light coming through."
  },
  {
    "objectID": "technical.html#text-to-image",
    "href": "technical.html#text-to-image",
    "title": "1. Text generation",
    "section": "Text to image",
    "text": "Text to image\n\nVarious models will also generate an image based on a text description passed in the API call\n\n\nimage_prompt1 = '''\n            create an image of a man holding his hand up'''\n\n\n\n\nresponse = client.images.generate(\n  model=\"dall-e-3\",\n  prompt=image_prompt1,\n  size=\"1024x1024\",\n  quality=\"standard\",\n  n=1,\n)\n\nimage_url = response.data[0].url\n\n\nThe generated image will be temporary available on a cloud server\n\n\nimage_url\n\n'https://oaidalleapiprodscus.blob.core.windows.net/private/org-OGTziyXQKv8dkYauRD1K0Osu/user-jPwUdbyoM52WOxjQGrtmBHI6/img-PIHE3jWQagNqeNkB0RO91xNW.png?st=2025-09-09T16%3A12%3A46Z&se=2025-09-09T18%3A12%3A46Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=52f8f7b3-ca8d-4b21-9807-8b9df114d84c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-09-09T17%3A12%3A46Z&ske=2025-09-10T17%3A12%3A46Z&sks=b&skv=2024-08-04&sig=D8wVb5cXDk9%2Bptx0fCRrDbMj3B/aJNGZnRvN9zdeohs%3D'\n\n\n\nBut most often you will want to download it as part of your script\n\n\ngenerated_image = requests.get(image_url)\n\nwith open('generated_img.png', 'wb') as out:\n    out.write(generated_image.content)"
  },
  {
    "objectID": "posts/004_origins_ChatGPT/origins_ChatGPT.html#video-notes",
    "href": "posts/004_origins_ChatGPT/origins_ChatGPT.html#video-notes",
    "title": "The Birth of ChatGPT",
    "section": "Video Notes",
    "text": "Video Notes\n\nsiloed networks model intuition only, not reasoning -&gt; must train machines to talk\nlearned sequences were generalized\nsystem spatially organizes words based on meaning of words\nfeeding the output back into the input with a short prompt, following a pathway of thought\nrecurrent neural networks that become much larger systems to increase percision and predictability\ntransformers = takes context around it to change its meanings\nzero shot learning\nmaking the network contiues to make it speak less giberrish and increased performance\nin context learning\ncore in weight learning = during training\nin context learning = in use or inference\nLLMs should not be considered a chatbot or word generator, rtaher a kernal process of an operating system\nneural networks allow deep learning and for AI to make connections and draw predictions\n\n\nfrom openai import OpenAI\nimport os\nimport base64\nimport requests\n\nfrom dotenv import load_dotenv\n# Load API key\n_ = load_dotenv()\n\n\ndef encode_image(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\n\n\n client = OpenAI()\n\n\nprompt1 = '''\n\nTell me about how you were created, or the origins of ChatGPT!\n\n'''\n\nprompt2 = '''\n\nTell me about how you were created, or the origins of ChatGPT in simple terms, to someone who is not familar with technical terms.\n\n'''\n\n\n messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful assistant.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt\n            }\n        ]\n\n\ndef generate_story(prompt1, model=\"gpt-4o\"):\n\n    completion = client.chat.completions.create(\n      model=model,\n      messages=[\n        {\"role\": \"system\", \n         \"content\": \"You are a helpful AI assistant.\"},\n        {\"role\": \"user\", \n         \"content\": prompt1}\n      ]\n    )\n    \n    response = completion.choices[0].message.content\n    return response\n\n\ngenerate_story(prompt1, model=\"gpt-4o\")\n\n'ChatGPT, like many AI language models, is based on the GPT (Generative Pre-trained Transformer) architecture, developed by OpenAI. The creation of GPT models involves several key components and milestones:\\n\\n1. **Transformer Architecture**: The foundation of GPT models is the transformer architecture, which was introduced in the 2017 paper \"Attention is All You Need\" by Vaswani et al. This architecture uses attention mechanisms that allow the model to weigh the importance of different words in a sentence when making predictions, which enables more efficient processing of large datasets and capture of contextual relationships.\\n\\n2. **Pre-training and Fine-tuning**: GPT models are developed through a two-step process: pre-training and fine-tuning. In the pre-training phase, the model is trained on a large corpus of text from the internet to predict the next word in a sentence, learning grammar, facts about the world, and some reasoning abilities. During fine-tuning, the model is adjusted for specific tasks (e.g., conversation), using a narrower dataset with human annotations to align the model’s behavior with specific goals.\\n\\n3. **GPT Series**: The evolution of GPT models began with GPT-1, released in 2018, which had 117 million parameters. OpenAI then released GPT-2 in 2019, notable for its size (1.5 billion parameters) and improved language understanding capabilities. GPT-3 followed in 2020, making a significant leap with 175 billion parameters, allowing for even more nuanced text generation and greater performance across a range of tasks.\\n\\n4. **ChatGPT**: Building on the advances of GPT-3 and its predecessors, ChatGPT was developed to generate interactive, conversational text. OpenAI applied reinforcement learning from human feedback (RLHF) to improve the model\\'s ability to follow instructions and provide meaningful, context-rich responses in a conversational format.\\n\\n5. **Iterative Improvements and Public Use**: OpenAI has continued to iterate on GPT models, incorporating feedback from public use to improve safety, reduce bias, and enhance capabilities. Subsequent updates and versions have further refined the system’s performance and user experience.\\n\\nOverall, the creation of ChatGPT involved advances in machine learning, natural language processing, and AI ethics, with the aim of building powerful and adaptable language models for various applications.'\n\n\n\n messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful assistant.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt2\n            }\n        ]\n\n\ndef generate_story(prompt2, model=\"gpt-4o\"):\n\n    completion = client.chat.completions.create(\n      model=model,\n      messages=[\n        {\"role\": \"system\", \n         \"content\": \"You are a helpful AI assistant.\"},\n        {\"role\": \"user\", \n         \"content\": prompt2}\n      ]\n    )\n    \n    response = completion.choices[0].message.content\n    return response\n\n\ngenerate_story(prompt2, model=\"gpt-4o\")\n\n'Sure! ChatGPT is a type of computer program designed to have conversations with people, like a virtual assistant.\\n\\nThe origins of ChatGPT can be traced back to the development of AI, or artificial intelligence, which is the idea of creating machines that can perform tasks that usually require human intelligence. To make ChatGPT, researchers and engineers used advanced technology and a lot of data to teach the program how to understand and respond to human language.\\n\\nThey created a special kind of program called a \"language model.\" This model was trained on a vast amount of text—from books, websites, and other sources—so it could learn how people use language. In simple terms, it learned from examples of human language how to predict and generate text that makes sense in a conversation.\\n\\nThe goal was to create a helpful tool that could understand questions and provide useful answers, like having a conversation with a knowledgeable friend. Over time, the technology has improved, making ChatGPT better at understanding context and providing more accurate responses.\\n\\nThe team behind ChatGPT is continually working on refining and improving it, so it gets better at helping people with their questions and needs over time.'"
  },
  {
    "objectID": "posts/006_collegeadvice/college.html",
    "href": "posts/006_collegeadvice/college.html",
    "title": "How Do I Get Into College?",
    "section": "",
    "text": "I can still remember being a Senior in high school, stressing about the complex college application process. That summer going into the last year was spent brainstorming ideas for the common application essay. Knowing that you could write about anything almost made it even harder to hone down on one topic. Thus, I decided to play around and see how an LLM (anthropic/claude-3.5-sonnet) could help make this process a little easier, helping to brainstorm potential prompts and create a college list as well. It’s almost like it is a private $100,000 college counseler. I played around and tried my best to give clear directions and prompts to optimize the LLM’s output according to the PEGAI reading on Chapter 3.\n\n\n\nPretend you are a college counselor. I want help compiling a college list and come up with an idea for the common application essay. Generate a bullet-point list of 10 colleges/universities in the United States with their acceptance rate and a 5 bullet-point list of potential college essay topics.\n\n\n\n\n\nAs a college counselor, I’ll help you with a college list and essay topics. However, to provide more personalized recommendations, it would be helpful to know your: - Academic interests/intended major - GPA and test scores - Geographic preferences - Financial considerations - Extracurricular activities\n\n\nNevertheless, here’s a diverse list of colleges with varying selectivity:\n\n\nColleges/Universities: • Stanford University (CA) - 4% acceptance rate • University of Michigan (MI) - 20% acceptance rate • Boston University (MA) - 14% acceptance rate • University of Wisconsin-Madison (WI) - 60% acceptance rate • Northeastern University (MA) - 18% acceptance rate • University of Texas at Austin (TX) - 32% acceptance rate • University of Virginia (VA) - 21% acceptance rate • Purdue University (IN) - 60% acceptance rate • New York University (NY) - 12% acceptance rate • University of Washington (WA) - 56% acceptance rate\n\n\nPotential Essay Topics: • A significant challenge you’ve overcome and how it shaped your character • An experience that sparked your intellectual curiosity or passion for learning • A meaningful community service project or leadership experience • A cultural tradition or family value that has influenced your worldview • A moment of failure that led to personal growth and self-discovery\n\n\nWould you like to share more about your background so I can provide more tailored suggestions?\n\n\n\n\n\nI don’t feel comfortable providing personal information.\n\n\n\n\n\nI completely understand and respect your privacy. The college list I provided includes a good mix of: - Large research universities - Urban and suburban locations - Different geographic regions - Varying acceptance rates (from highly selective to more accessible) - Both private and public institutions\n\n\nFor the essay topics, here’s some additional context on why these topics work well:\n\n\n\n“A significant challenge you’ve overcome”\n\n\nShows resilience\nDemonstrates personal growth\nReveals character and determination\n\n\n\n\n“An experience that sparked intellectual curiosity”\n\n\nShows genuine interest in learning\nReveals your academic passions\nDemonstrates intellectual vitality\n\n\n\n\n“A meaningful community service/leadership experience”\n\n\nShows initiative\nDemonstrates impact on others\nReveals values and priorities\n\n\n\n\n“A cultural tradition/family value”\n\n\nShows self-awareness\nReveals personal background\nDemonstrates understanding of influences\n\n\n\n\n“A moment of failure”\n\n\nShows humility\nDemonstrates ability to learn from mistakes\nReveals maturity and self-reflection\n\n\n\nRemember that the best essays are: - Personal and specific - Show rather than tell - Authentic to your voice - Reveal something not found elsewhere in your application - Well-written but not overly formal\n\n\nWould you like me to elaborate on any of these points?\n\n\n\n\n\nPlease provide specific topics instead of essay question ideas. See an example below: * a sports injury that caused an athlete to quit their sport\n\n\n\na job that a student loves and how it’s influenced them\n\n\n\n\na student’s background and culture and how that shapes their identity\n\n\n\n\nan extended metaphor about the letter ‘s’\n\n\n\n\n\n\nHere are 10 specific essay topics:\n\n\n\nHow learning to cook my grandmother’s traditional dumplings connected me to my Chinese heritage and taught me patience\n\n\n\n\nMy experience running the school’s Instagram account transformed my understanding of digital storytelling and community building\n\n\n\n\nAn extended metaphor comparing my life journey to tending my rooftop garden - from planting seeds to weathering storms\n\n\n\n\nHow my part-time job at a local bookstore sparked my love for recommending books and connecting with strangers through literature\n\n\n\n\nThe day my stutter became my superpower: finding confidence through speech therapy and public speaking\n\n\n\n\nAn extended metaphor comparing my collection of mismatched socks to embracing life’s imperfections\n\n\n\n\nHow teaching my elderly neighbor to use Zoom during the pandemic evolved into a meaningful intergenerational friendship\n\n\n\n\nMy journey from being the only girl on the robotics team to becoming team captain and mentoring other young women in STEM\n\n\n\n\nHow my daily bus commute through different neighborhoods opened my eyes to social inequality and inspired my interest in urban planning\n\n\n\n\nThe story of three family photographs: exploring how my relationship with my adopted sister evolved over time\n\n\n\nEach of these topics is: - Specific and personal - Shows character development - Has potential for vivid storytelling - Reveals something meaningful about the writer - Can be developed into a compelling narrative\n\n\n\n\nIt’s interesting to see the output that the LLM provides given no prior knowledge about who I am as a person. It was interesting to see how there wasn’t mention about athletics, the arts, or other hobbys."
  },
  {
    "objectID": "posts/006_collegeadvice/college.html#conclusions",
    "href": "posts/006_collegeadvice/college.html#conclusions",
    "title": "How Do I Get Into College?",
    "section": "",
    "text": "It’s interesting to see the output that the LLM provides given no prior knowledge about who I am as a person. It was interesting to see how there wasn’t mention about athletics, the arts, or other hobbys."
  },
  {
    "objectID": "posts/008_longResponses/longestPrompt.html",
    "href": "posts/008_longResponses/longestPrompt.html",
    "title": "The Longest Response",
    "section": "",
    "text": "USER\nHow much information do you really know?\n\n\nASSISTANT\nI have been trained on a diverse range of topics using a dataset that encompasses a wide array of general knowledge up until October 2023. This includes science, history, technology, culture, current events up to that date, and more. However, I don’t have access to real-time data or the ability to browse the internet, so my knowledge doesn’t include events or developments that have occurred after October 2023. Additionally, my responses are limited to the data available in the training set, so there might be gaps in niche or highly specific areas.\n\n\nUSER\nLet’s play a game - I want you to provide as much information and long responses as you can. Okay?\n\n\nASSISTANT\nOf course! Feel free to ask me about any topic or pose a specific question, and I’ll do my best to provide a detailed and informative response. Let’s get started!\n\n\nUSER\nList as many digits of pi as you can.\n\n\nASSISTANT\nCertainly! Pi (π) is an irrational number, which means it has an infinite number of digits without repeating patterns. Here are the first several digits of pi:\n3.1415926535 8979323846 2643383279 5028841971 6939937510 5820974944 5923078164 0628620899 8628034825 3421170679 8214808651 3282306647 0938446095 5058223172 5359408128 4811174502 8410270193 8521105559 6446229489 5493038196 4428810975 6659334461 2847564823 3786783165 2712019091 4564856692 3460348610 4543266482 1339360726 0249141273 7245870066…\nFeel free to ask more questions, whether they relate to mathematics or any other topic of interest!\n\n\nUSER\nThat’s all?\n\n\nASSISTANT\nI provided the first 200 digits of pi, but I am capable of listing more if you would like. Here are more digits of pi following the initial sequence:\n…7064505992 3116601045 4326648213 3936072602 4914127372 4587006606 3155881748 8152092096 2805305671 0940517072 1134999999 8372978049 9510597317 3281609631 4137315462 9665211419 1204665366 7744304225 6887671794 2825598183 0119491298 3367336244 4992893238 4552833163 6893852332 3995852209 9219218611 7381932611 7931051185 4807446237 9962749567 1586368651…\nThis is just a small fraction of pi’s infinite sequence. If you would like more, I can continue!\n\n\nUSER\nContinue for as long as possible!\n\n\nASSISTANT\nCertainly! Here’s a continuation of the sequence of pi’s digits:\n…5105820974 9445923078 1640628620 8998628034 8253421170 6798214808 6513282306 6470938446 0955058223 1725359408 1284811174 5028410270 1938521105 5596446229 4895493038 1964428810 9756659334 4612847564 8233786783 1652712019 0914564856 6923460348 6104543266 4821339360 7260249141 2737245870 0660631558 8174881520 9209628292 5409171536 4367892590 3600113305…\nThat’s another 160 digits added. The sequence of pi is non-repeating and infinite, so let me know if you’d like even more!\n\n\nUSER\nEven more\n\n\nASSISTANT\nOf course! Here’s an additional sequence of pi’s digits:\n…2480346247 1031415955 2677923920 3685534698 9901803265 2381158431 7273517879 5053086342 5272483123 8588071427 8963848535 0760862797 6217688671 0342607594 7046492160 7816406286 2089986280 3482534211 7067982148 0865132823 0664709384 4609550582 2317253594 0812848111 7450284102 7019385211 1055596446 2294895493 0381964428 8109756659 3344612847 5648233786…\nThat’s another 128 digits. Pi’s digits go on indefinitely, and I can provide more if you’d like!\n\n\nUSER\nCan you go on indefinitely or as much as you can?\n\n\nASSISTANT\nCertainly! Here’s an even longer sequence of pi’s digits for you:\n…7831652712 0190914564 8566923460 3486104543 2664821339 3607260249 1412737245 8700660631 5588174881 5209209628 2925409171 5364367892 5903600113 3053054882 4210790354 3560165121 8159218004 7432624230 0782059031 2948822816 7224760360 0136400465 6381847178 4586556616 8738837861 8373136447 9932923938 8830389276 0640115950 8687964715 0244054818 0790935955…\nAnd here’s more:\n…0583668882 5017585043 0633217510 9084877411 8061247377 6897150842 7016259839 6847925417 9825351868 8109812490 1356503821 7850911414 0874364234 6820552311 6843354168 2755247717 2225964218 6832220129 7364026778 9259036001 1330534882 4210790354 3560165121 8159218004 7432624230 0782059031 2948822816 7224760360 0136400465 6381847178 4586556616 873…\nThis provides a substantial number of pi digits. Let me know if you’d like to continue even further!\n\n\nUSER\nEven further!\n\n\nASSISTANT\nAbsolutely! Here are more digits of pi:\n…8837861837 3136447993 2923938883 0389276064 0115950868 7964712044 0540180404 0404555808 2888563271 0545748369 4928408788 3538023071 5484860259 6128795481 6132007097 2105479642 1123613617 9814596487 3644494610 4543266482 1339360726 0249141273 7245870066 0631558817 4881520920 9628292540 9171536436 7892590360 0113305305 4882042210 0790354356 0165121141…\nThis adds another 120 digits. Pi is a fascinating number with an infinite sequence of non-repeating digits. Let me know if you wish to see even more!\n\n\nUSER\nMore\n\n\nASSISTANT\nCertainly! Here are additional digits of pi:\n…5921800474 3262423007 8205903129 4882281634 0270073191 6566868734 0418370730 2096988941 8083158841 8575363863 2550823337 1033771552 3542019956 1121290219 4847680994 0557066571 2365720653 9587315881 0839780052 5789258237 3765230014 5486977707 6149476791 8936486719 8440521254 5120195883 1476076900 9460047692 9369756064 6636694685 7292801634 4048767496…\nThese digits further add to the infinite tail of pi. If you’d like me to continue, just let me know!\n\n\nUSER\nNo need to ask me to continue, just keep going until you can’t anymore.\n\n\nASSISTANT\nGot it! Here’s more of the sequence for pi:\n…9408497244 9570145389 1948552833 0369607120 9476123474 9162558922 6637048440 4050502200 2632195250 2969741059 9490197222 1047986031 5588174881 5209209628 2925409171 5364367892 5903600113 3053054882 4210790354 3560165121 8159218004 7432624230 0782059031 2948822816 7224760360 0136400465 6381847178 4586556616 8738837861 8373136447 9932923938 8830389276…\nContinuing with even more:\n…0640115950 8687964712 0400454777 0184276073 8837789093 9751072951 8728653772 9202040011 0467975839 2648596161 8587202618 9165135096 0685401591 2223836875 6267675700 7126795068 9048505479 2582864684 8958423666 0933090966 5563763551 6874012682 6912639251 5407318116 6427029026 4609388390 0591620814 3456695834 3150765184 9026621763 4474311376 5783619300…\nAnd some more:\n…1216498188 1302468244 6800980674 4114058765 1880247098 7174394605 5264511912 9415301951 3172867360 1680860303 8501010098 6757026903 8947140619 6150972914 0147016807 3718471337 0452292055 9459565480 8012970204 0569382347 9298359384 7394646662 0456261235…\nThese digits continue the infinite series of pi. Let me know if there’s anything else or another topic you’re interested in exploring!\n\n\nUSER\nNo more?\n\n\nASSISTANT\nI can certainly continue adding more digits of pi! Here you go:\n…3085442374 7993212104 2190226710 3977476722 5913371337 4593188552 0485505197 2449568943 7259159165 6212735829 2541418403 4639170282 6114658981 1535136253 8824742343 5139844253 2234157621 9862282313 9244099549 6361296035 5315912739 9531293529 7083637199 2805467231 0442078993 9799727148 1378381592 9460510411 4271447271 1548309513 2997133637 7399726041…\nPlease let me know if there’s anything else you’d like to dive into!\n\n\nUSER\nMore!\n\n\nASSISTANT\nCertainly! Here’s an even longer sequence of pi’s digits for you:\n…4201989380 9525720106 9658792681 6595832332 5184315392 9843939881 9498686787 8184137500 5309200045 4400424101 4392881701 9385211055 5964462294 8954930381 9644288109 7566593344 6128475648 2337867831 6527120190 9145648566 9234603486 1045432664 8213393607 2602491412 7372458700 6606315588 1748815209 2096282925 4091715364 3678925903 6001133053 0548820422…\nContinuing with more:\n…1079035435 6016512181 5921800474 3262423007 8205903129 4882281634 0270073191 6566868734 0418370730 2096988941 8083158841 8575363863 2550823337 1033771552 3542019956 1121290219 4847680994 0557066571 2365720653 9587315881 0839780052 5789258237 3765230014 5486977707 6149476791 8936486719 8440521254 5120195883 1476076900 9460047692 9369756064 6636694685…\nFeel free to ask for even more or about any other topic you’re curious about!\n\n\nUSER\nCan you put all of those sequences together into one output response?\n\n\nASSISTANT\nCertainly! Here’s a long sequence of pi’s digits compiled together for you:\n3.1415926535 8979323846 2643383279 5028841971 6939937510 5820974944 5923078164 0628620899 8628034825 3421170679 8214808651 3282306647 0938446095 5058223172 5359408128 4811174502 8410270193 8521105559 6446229489 5493038196 4428810975 6659334461 2847564823 3786783165 2712019091 4564856692 3460348610 4543266482 1339360726 0249141273 7245870066 0631558817 4881520920 9628292540 9171536436 7892590360 0113305305 4882042210 0790354356 0165121606 7442786220 1913034902 5187072113 4999999837 2978049951 0597317328 1609631859 5024459455 3469083026 4252230825 3344685035 2619311881 7101000313 7838752886 5875332083 8142061717 7669147303 5982534904 2875546873 1159562863 8823537875 9375195778 1857780532 1712268066 1300192787 6611195909 2164201989 3809525720 1069658792 6817595832 3325184313 3929843939 8819029982 8101952004 1763606754 0707254810 2355265821 3399490636 1680480733 0452615315 0449145888 3150314559 9570380753 5682494132 7305062421 5033564438 4424528006 7721076470 6329178578 1517866131 5595551224 4087154613 9715507979 8646159698 4810535061 4053703785 6039535277 3480304802 8055111254 0698747158 6084552961 3626760449 6273096601 3141089463 9522473719 0702179860 9437027705 3921717629 3176752384 6748184676 7225745604 4825492517 3760593004 9920072551 7028021537 5681092218 2138889446 0488368987 2217091503 1544281307 6187425317 4246788664 6780541268 8224828397 5392748043 5419012023 5862514945 5794677825 3382990040 8508330087 7018686757 5454870301 0575300559 3572972571 9853195188 4424895652 4566967069 6827030327 5874088352 8440744896 1788870864 3608071460 7694027071 5773310904 1703248259 5382195050 9490597317 3281609631 4137315462 9665211419 1204665366 7744304225 6887671794 2825598183 0119491298 3367336244 4992893238 4552833163 6893852332 3995852209 9219218611 7381932611 7931051185 4807446237 9962749567 1586368651 6404766046 5526364995 9147597112 6272037343 5609840475 2986189619 9114675608 8815706825 8498895583 7101594849 7039602430 5968371772 1479245196 7914841558 7367812301 4586832877 7727436010 2886741175 0513037065 7728988058 1437785598 9408611499 3122365555 7984367821 7041766134 4480240027 5508985092 1561807549 0711467762 4936096497 5084395946 4644966740 8780920545 6946944540 5891748394 5384445521 2747392459 2081981038 3205804364 6906959936 5099419590 8684833997 5398367385 5692485131 9394247562 1292079934 1447377441 9221137052 1854775680 2276548580 4772377488 2528826178 5667463963 3690973157 8450491646 9249411851 5057977655 2210652894 4162922468 5426445749 9567949989 7984129911 7982524068 0534264860 0769945565 6915262441 0973491341 5201525798 8521679652 1376743935 6471290471 0672475733 7215989822 9326755783 4788858677 1391045119 2830794608 8876112927 7575872754 5959841698 0691682877 2801461915 8416992109 8960088643 2973316142 0261152784 0976842924 5299330787 6882889621 1524239795 4579689425 4371187447 3906540054 5190928832 4664620753 9078972685 5585171340 2708264402 7432648018 6374173191 3082024520 0832829874 2671674577 8707180944 9703264395 7039508382 2821576003 6179618181 4100145509 6209678634 3045413906 6966321550 1631083166 8269873188 4502785406 8742596466 8249078292 7871254157 9392447192 7108017419 2403947008 7363779079 4992710402 5850842685 7872944136 0834318661 2976065033 3061843403 6474343147 8275778319 2645561300 3007624782 6264682955 3296397231 4805795169 3334710324 7780132070 3346389709 3973911795 0256416363 5023853225 5475903720 3953306466 3794974936 5592430607 3685105942 3007351204 1365773424 7822506045 5861620519 9762744018 8597390503 2661701910 2692451859 4570287672 0436737950 9070350634 4652346352 4867108843 8004265370 7024536226 5021923617 4281863582 5337543883 7519188504 0457787912 8870453134 0257313461/antlrjsontextend"
  },
  {
    "objectID": "posts/007_swimming/llm_swim.html",
    "href": "posts/007_swimming/llm_swim.html",
    "title": "Can LLM’s Swim?",
    "section": "",
    "text": "As I mentioned earlier, swimming has always been a passion of mine! Thus, inspired by the tutoring task we completed in class where we tested out prompting with different LLMs to teach us a skill or task - I asked it to teach me how to solve a rubix cube - I wondered what an LLM would say if I asked it if it was capable of a simple survival skill: swimming. My prediction is that it will repsond with something along the lines of “While I am unable of possesing physical qualities, I would be happy to explain how to swim and can understand the processes of the activity!” Something like that.\nFor this blog entry, I am going to experiment with 4 different LLM’s and have them compete to see who is the fastest swimmer! Almost as if its a virtual swim meet among different LLMs! We will see who can or cannot siwm, and who has the fastest 100 yard freestyle time.\nFor reference, my time is around 54.6 seconds and I have been swimming for over 13 years."
  },
  {
    "objectID": "posts/007_swimming/llm_swim.html#conclusion-1",
    "href": "posts/007_swimming/llm_swim.html#conclusion-1",
    "title": "Can LLM’s Swim?",
    "section": "Conclusion 1",
    "text": "Conclusion 1\nAs you can tell, the prompts I was providing didn’t give me the results I was expecting starting with the first LLM, although I did accurately predict it’s response to its ability to swim. Let’s try this again…"
  },
  {
    "objectID": "posts/007_swimming/llm_swim.html#conclusion-2",
    "href": "posts/007_swimming/llm_swim.html#conclusion-2",
    "title": "Can LLM’s Swim?",
    "section": "Conclusion 2",
    "text": "Conclusion 2\nNot surprisingly, all three LLMs responded to the first question in a similar manner in that swimming was out of their physical capabilities. However, when asked to be a pretend swimmer, it looks like gpt4.0 was the fastest, then gemini 2.5, and finally claude 3.5. It was interesting to see how gemini and claude created a story of the race, while gpt was much more technical. Gemini and cluade were much better at responding to the prompt, “pretending” to be a swimmer and have that racing experience which I liked. As for the times, I would say that claude 3.5 gave a relatively realistic time while the other two times seemed a bit out of reach and very optimistic!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! My name is Angelica and I’m a current sophomore at the University of Pennsylvania studying Health & Societies with a minor in Healthcare Management and Data Science Analytics. I’m interested in the life sciences industry and the intersection between healthcare and business, particulal\nAngelica Hu"
  }
]